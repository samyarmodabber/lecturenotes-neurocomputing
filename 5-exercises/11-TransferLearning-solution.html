
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11.2. Transfer learning &#8212; Neurocomputing</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystyle.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://julien-vitay.net/lecturenotes-neurocomputing/5-exercises/11-TransferLearning-solution.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12. Variational autoencoder" href="ex12-VAE.html" />
    <link rel="prev" title="11.1. Transfer learning" href="11-TransferLearning.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://julien-vitay.net/lecturenotes-neurocomputing/5-exercises/11-TransferLearning-solution.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Transfer learning" />
<meta property="og:description" content="Transfer learning  The goal of the exercise is to investigate data augmentation and transfer learning on a very small dataset (2000 training images).  The code " />
<meta property="og:image"       content="https://julien-vitay.net/lecturenotes-neurocomputing/_static/tuc.svg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/tuc.svg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neurocomputing</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Neurocomputing
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../1-intro/1-Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../1-intro/2-Math.html">
   2. Math basics (optional)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../1-intro/3-Neurons.html">
   3. Neurons
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/1-Optimization.html">
   1. Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/2-LinearRegression.html">
   2. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/3-Regularization.html">
   3. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/4-LinearClassification.html">
   4. Linear classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/5-Multiclassification.html">
   5. Multi-class classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-linear/6-LearningTheory.html">
   6. Learning theory
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/1-NN.html">
   1. Artificial neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/2-DNN.html">
   2. Deep neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/3-CNN.html">
   3. Convolutional neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/4-ObjectDetection.html">
   4. Object detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/5-SemanticSegmentation.html">
   5. Semantic segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/6-Autoencoders.html">
   6. Autoencoders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/7-RBM.html">
   7. Restricted Boltzmann machines (optional)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/8-GAN.html">
   8. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-deeplearning/9-RNN.html">
   9. Recurrent neural networks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Neurocomputing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../4-neurocomputing/1-Limits.html">
   1. Limits of deep learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4-neurocomputing/2-Hopfield.html">
   2. Hopfield networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4-neurocomputing/4-Reservoir.html">
   3. Reservoir computing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4-neurocomputing/5-Hebbian.html">
   4. Unsupervised Hebbian learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4-neurocomputing/6-Spiking.html">
   5. Spiking neural networks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex1-Python.html">
   1. Introduction to Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="1-Python.html">
     1.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="1-Python-solution.html">
     1.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex2-Numpy.html">
   2. Numpy and Matplotlib
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="2-Numpy.html">
     2.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2-Numpy-solution.html">
     2.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex3-LinearRegression.html">
   3. Linear regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="3-LinearRegression.html">
     3.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3-LinearRegression-solution.html">
     3.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex4-MLR.html">
   4. Multiple Linear Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="4-MLR.html">
     4.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="4-MLR-solution.html">
     4.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex5-Crossvalidation.html">
   5. Cross-validation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-Crossvalidation.html">
     5.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-Crossvalidation-solution.html">
     5.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex6-LinearClassification.html">
   6. Linear classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="6-LinearClassification.html">
     6.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="6-LinearClassification-solution.html">
     6.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex7-SoftmaxClassifier.html">
   7. Softmax classifier
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="7-SoftmaxClassifier.html">
     7.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="7-SoftmaxClassifier-solution.html">
     7.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex8-MLP.html">
   8. Multi-layer perceptron
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="8-MLP.html">
     8.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="8-MLP-solution.html">
     8.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex9-MNIST.html">
   9. MNIST classification using keras
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="9-MNIST.html">
     9.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="9-MNIST-solution.html">
     9.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex10-CNN.html">
   10. Convolutional neural networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="10-CNN.html">
     10.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10-CNN-solution.html">
     10.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="ex11-TransferLearning.html">
   11. Transfer learning
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="11-TransferLearning.html">
     11.1. Notebook
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex12-VAE.html">
   12. Variational autoencoder
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="12-VAE.html">
     12.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-VAE-solution.html">
     12.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="ex13-RNN.html">
   13. Recurrent neural networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="13-RNN.html">
     13.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-RNN-solution.html">
     13.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../zreferences.html">
   1. Bibliography
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/5-exercises/11-TransferLearning-solution.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/vitay/lecturenotes-neurocomputing/master?urlpath=tree/neurocomputing/5-exercises/11-TransferLearning-solution.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/vitay/lecturenotes-neurocomputing/blob/master/neurocomputing/5-exercises/11-TransferLearning-solution.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-the-cats-and-dogs-data">
   11.2.1. Loading the cats and dogs data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functional-api-of-keras">
   11.2.2. Functional API of Keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-a-cnn-from-scratch">
   11.2.3. Training a CNN from scratch
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-augmentation">
   11.2.4. Data augmentation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   11.2.5. Transfer learning
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="transfer-learning">
<h1><span class="section-number">11.2. </span>Transfer learning<a class="headerlink" href="#transfer-learning" title="Permalink to this headline">¶</a></h1>
<p>The goal of the exercise is to investigate data augmentation and transfer learning on a very small dataset (2000 training images).</p>
<p>The code is based on the keras tutorial:</p>
<p><a class="reference external" href="https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs">https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs</a></p>
<p>The data is provided as part of a Google tutorial:</p>
<p><a class="reference external" href="https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb">https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="loading-the-cats-and-dogs-data">
<h2><span class="section-number">11.2.1. </span>Loading the cats and dogs data<a class="headerlink" href="#loading-the-cats-and-dogs-data" title="Permalink to this headline">¶</a></h2>
<p>The data we will use is a subset of the <a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/data">“Dogs vs. Cats” dataset</a> dataset available on Kaggle, which contains 25,000 images. Here, we use only 1000 dogs and 1000 cats to decrease training time and make the problem harder.</p>
<p>The following cell downloads the data and decompresses it in <code class="docutils literal notranslate"><span class="pre">/tmp/</span></code> (it will be erased at the next restart of your computer).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget --no-check-certificate <span class="err">\</span>
    <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">storage</span><span class="o">.</span><span class="n">googleapis</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mledu</span><span class="o">-</span><span class="n">datasets</span><span class="o">/</span><span class="n">cats_and_dogs_filtered</span><span class="o">.</span><span class="n">zip</span> \
    <span class="o">-</span><span class="n">O</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">cats_and_dogs_filtered</span><span class="o">.</span><span class="n">zip</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>

<span class="n">local_zip</span> <span class="o">=</span> <span class="s1">&#39;/tmp/cats_and_dogs_filtered.zip&#39;</span>
<span class="n">zip_ref</span> <span class="o">=</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">local_zip</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;/tmp&#39;</span><span class="p">)</span>
<span class="n">zip_ref</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2020-12-23 11:23:19--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.63.128, 142.250.31.128, 172.217.7.176, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.63.128|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 68606236 (65M) [application/zip]
Saving to: ‘/tmp/cats_and_dogs_filtered.zip’

/tmp/cats_and_dogs_ 100%[===================&gt;]  65.43M   183MB/s    in 0.4s    

2020-12-23 11:23:20 (183 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]
</pre></div>
</div>
</div>
</div>
<p>All we have is a bunch of <code class="docutils literal notranslate"><span class="pre">*.jpg</span></code> images organized in a training and validation set, separated by their binary class dog vs. cat:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cats_and_dogs_filtered</span><span class="o">/</span>
    <span class="n">train</span><span class="o">/</span>
        <span class="n">dogs</span><span class="o">/</span>
            <span class="n">dog001</span><span class="o">.</span><span class="n">jpg</span>
            <span class="n">dog002</span><span class="o">.</span><span class="n">jpg</span>
            <span class="o">...</span>
        <span class="n">cats</span><span class="o">/</span>
            <span class="n">cat001</span><span class="o">.</span><span class="n">jpg</span>
            <span class="n">cat002</span><span class="o">.</span><span class="n">jpg</span>
            <span class="o">...</span>
    <span class="n">validation</span><span class="o">/</span>
        <span class="n">dogs</span><span class="o">/</span>
            <span class="n">dog001</span><span class="o">.</span><span class="n">jpg</span>
            <span class="n">dog002</span><span class="o">.</span><span class="n">jpg</span>
            <span class="o">...</span>
        <span class="n">cats</span><span class="o">/</span>
            <span class="n">cat001</span><span class="o">.</span><span class="n">jpg</span>
            <span class="n">cat002</span><span class="o">.</span><span class="n">jpg</span>
            <span class="o">...</span>
</pre></div>
</div>
<p>Feel free to download the data on your computer and have a look at the images directly.</p>
<p>The next cell checks the structure of the image directory:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;/tmp/cats_and_dogs_filtered&#39;</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">base_dir</span> <span class="o">+</span> <span class="s1">&#39;/train&#39;</span>
<span class="n">validation_dir</span> <span class="o">=</span> <span class="n">base_dir</span> <span class="o">+</span> <span class="s1">&#39;/validation&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total training cat images:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/cats&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total training dog images:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/dogs&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total validation cat images:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">validation_dir</span> <span class="o">+</span> <span class="s1">&#39;/cats&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total validation dog images:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">validation_dir</span> <span class="o">+</span> <span class="s1">&#39;/dogs&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500
</pre></div>
</div>
</div>
</div>
<p>The next cell visualizes some cats and dogs from the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">1000</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">next_cat_pix</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/cats&#39;</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span> <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/cats&#39;</span><span class="p">)[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">8</span><span class="p">]]</span>
<span class="n">next_dog_pix</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/dogs&#39;</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span> <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/dogs&#39;</span><span class="p">)[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">8</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">next_cat_pix</span><span class="o">+</span><span class="n">next_dog_pix</span><span class="p">):</span>
  <span class="c1"># Set up subplot; subplot indices start at 1</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;Off&#39;</span><span class="p">)</span> <span class="c1"># Don&#39;t show axes (or gridlines)</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/11-TransferLearning-solution_8_0.png" src="../_images/11-TransferLearning-solution_8_0.png" />
</div>
</div>
<p>In order to train a binary classifier on this data, we would need to load the images and transform them into Numpy arrays that can be passed to tensorflow. Fortunately, keras provides an utility to do it automatically: <code class="docutils literal notranslate"><span class="pre">ImageDataGenerator</span></code>. Doc:</p>
<p><a class="reference external" href="https://keras.io/api/preprocessing/image/">https://keras.io/api/preprocessing/image/</a></p>
<p>The procedure is to create an <code class="docutils literal notranslate"><span class="pre">ImageDataGenerator</span></code> instance and to create an <strong>iterator</strong> with <code class="docutils literal notranslate"><span class="pre">flow_from_directory</span></code> that will return minibatches on demand when training the neural network. The main advantage of this approach is that you do not need to load the whole dataset in the RAM (not possible for most realistic datasets), but adds an overhead between each minibatch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="n">directory</span><span class="p">,</span>  <span class="c1"># This is the source directory for training images</span>
        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>  <span class="c1"># All images will be resized to 150x150</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="c1"># Since we use binary_crossentropy loss, we need binary labels</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">rescale</span></code> argument makes sure that the pixels will be represented by float values between 0 and 1, not integers between 0 and 255. Unfortunately, it is not possible (or very hard) to perform mean-removal using this method. The image data generator accepts additional arguments that we will discuss in the section on data augmentation.
<code class="docutils literal notranslate"><span class="pre">directory</span></code> must be set to the folder containing the images. We ask the generator to resize all images to 150x150 and will use a batch size of 64. As there are only two classes cat and dog, the labels will be binary (0 and 1).</p>
<p><strong>Q:</strong> Create two generators <code class="docutils literal notranslate"><span class="pre">train_generator</span></code> and <code class="docutils literal notranslate"><span class="pre">validation_generator</span></code> for the training and validation sets respectively, with a batch size of 64.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># All images will be rescaled by 1./255</span>
<span class="n">train_datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">val_datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>

<span class="c1"># Flow training images in batches </span>
<span class="n">train_generator</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="n">train_dir</span><span class="p">,</span>  
        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>  
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>

<span class="c1"># Flow validation images in batches</span>
<span class="n">validation_generator</span> <span class="o">=</span> <span class="n">val_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="n">validation_dir</span><span class="p">,</span>
        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</pre></div>
</div>
</div>
</div>
<p><strong>Q:</strong> Sample a minibatch from the training generator by calling <code class="docutils literal notranslate"><span class="pre">next()</span></code> on it (<code class="docutils literal notranslate"><span class="pre">X,</span> <span class="pre">t</span> <span class="pre">=</span> <span class="pre">train_generator.next()</span></code>) and display the first image. Call the cell multiple times.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">train_generator</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;Off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(64, 150, 150, 3)
</pre></div>
</div>
<img alt="../_images/11-TransferLearning-solution_12_1.png" src="../_images/11-TransferLearning-solution_12_1.png" />
</div>
</div>
</div>
<div class="section" id="functional-api-of-keras">
<h2><span class="section-number">11.2.2. </span>Functional API of Keras<a class="headerlink" href="#functional-api-of-keras" title="Permalink to this headline">¶</a></h2>
<p>In the previous exercises, we used the Sequential API of keras, which stacks layers on top of each other:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>In this exercise, we will use the Functional API of keras, which gives much more freedom to the programmer. The main difference is that you can explicitly specify from which layer a layer should take its inputs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>This allows to create complex architectures, for examples with several output layers.</p>
<p><strong>Q:</strong> Modify your CNN of last exercise so that it is defined with the Functional API and train it on MNIST.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fetch the MNIST data</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training data:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">t_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">t_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Normalize the values</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="c1"># Mean removal</span>
<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">-=</span> <span class="n">X_mean</span>
<span class="n">X_test</span> <span class="o">-=</span> <span class="n">X_mean</span>

<span class="c1"># One-hot encoding</span>
<span class="n">T_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">t_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">T_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">t_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Delete all previous models to free memory</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="c1"># Functional model</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

<span class="c1"># Learning rule</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Loss function</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="c1"># loss</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="c1"># learning rule</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="c1"># show accuracy</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">T_train</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">history</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">T_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
Training data: (60000, 28, 28) (60000,)
Test data: (10000, 28, 28) (10000,)
Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 5, 5, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1600)              0         
_________________________________________________________________
dense (Dense)                (None, 150)               240150    
_________________________________________________________________
dropout_2 (Dropout)          (None, 150)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1510      
=================================================================
Total params: 260,476
Trainable params: 260,476
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
844/844 [==============================] - 6s 4ms/step - loss: 1.0319 - accuracy: 0.6409 - val_loss: 0.0941 - val_accuracy: 0.9743
Epoch 2/20
844/844 [==============================] - 3s 3ms/step - loss: 0.2102 - accuracy: 0.9361 - val_loss: 0.0655 - val_accuracy: 0.9792
Epoch 3/20
844/844 [==============================] - 3s 3ms/step - loss: 0.1580 - accuracy: 0.9532 - val_loss: 0.0545 - val_accuracy: 0.9840
Epoch 4/20
844/844 [==============================] - 3s 4ms/step - loss: 0.1308 - accuracy: 0.9607 - val_loss: 0.0468 - val_accuracy: 0.9860
Epoch 5/20
844/844 [==============================] - 3s 3ms/step - loss: 0.1167 - accuracy: 0.9658 - val_loss: 0.0426 - val_accuracy: 0.9877
Epoch 6/20
844/844 [==============================] - 3s 3ms/step - loss: 0.1074 - accuracy: 0.9667 - val_loss: 0.0397 - val_accuracy: 0.9885
Epoch 7/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0381 - val_accuracy: 0.9888
Epoch 8/20
844/844 [==============================] - 3s 3ms/step - loss: 0.0961 - accuracy: 0.9706 - val_loss: 0.0357 - val_accuracy: 0.9898
Epoch 9/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0868 - accuracy: 0.9741 - val_loss: 0.0369 - val_accuracy: 0.9898
Epoch 10/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 0.0341 - val_accuracy: 0.9905
Epoch 11/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.0343 - val_accuracy: 0.9902
Epoch 12/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0788 - accuracy: 0.9753 - val_loss: 0.0352 - val_accuracy: 0.9897
Epoch 13/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0745 - accuracy: 0.9764 - val_loss: 0.0342 - val_accuracy: 0.9895
Epoch 14/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0707 - accuracy: 0.9787 - val_loss: 0.0325 - val_accuracy: 0.9908
Epoch 15/20
844/844 [==============================] - 3s 3ms/step - loss: 0.0693 - accuracy: 0.9790 - val_loss: 0.0312 - val_accuracy: 0.9912
Epoch 16/20
844/844 [==============================] - 3s 3ms/step - loss: 0.0696 - accuracy: 0.9779 - val_loss: 0.0314 - val_accuracy: 0.9907
Epoch 17/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0642 - accuracy: 0.9789 - val_loss: 0.0311 - val_accuracy: 0.9902
Epoch 18/20
844/844 [==============================] - 3s 4ms/step - loss: 0.0636 - accuracy: 0.9804 - val_loss: 0.0300 - val_accuracy: 0.9920
Epoch 19/20
844/844 [==============================] - 3s 3ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.0284 - val_accuracy: 0.9922
Epoch 20/20
844/844 [==============================] - 3s 3ms/step - loss: 0.0658 - accuracy: 0.9793 - val_loss: 0.0290 - val_accuracy: 0.9918
Test loss: 0.023223621770739555
Test accuracy: 0.9914000034332275
</pre></div>
</div>
<img alt="../_images/11-TransferLearning-solution_14_1.png" src="../_images/11-TransferLearning-solution_14_1.png" />
</div>
</div>
</div>
<div class="section" id="training-a-cnn-from-scratch">
<h2><span class="section-number">11.2.3. </span>Training a CNN from scratch<a class="headerlink" href="#training-a-cnn-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>Let’s now train a randomly-initialized CNN on the dog vs. cat data. You are free to choose any architecture you like, the only requirements are:</p>
<ul class="simple">
<li><p>The input image must be 150x150x3:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The output neuron must use the logistic/sigmoid activation function (binary classification:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The loss function must be <code class="docutils literal notranslate"><span class="pre">'binary_crossentropy'</span></code> and the metric <code class="docutils literal notranslate"><span class="pre">binary_accuracy</span></code>:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>There is not a lot of data, so you can safely go deep with your architecture (i.e. with convolutional layers and max-pooling until the image dimensions are around 7x7), especially if you use the GPU on Colab.</p>
<p>To train and validate the network on the generators, just pass them to <code class="docutils literal notranslate"><span class="pre">model.fit()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
      <span class="n">train_generator</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
      <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span>
      <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">history</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Q:</strong> Design a CNN and train it on the data for 30 epochs. A final validation accuracy around 72% -  75% is already good, you can then go to the next question.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">random_model</span><span class="p">():</span>
    <span class="c1"># Delete all previous models to free memory</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

    <span class="c1"># Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for</span>
    <span class="c1"># the three color channels: R, G, and B</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="c1"># First convolution extracts 16 filters that are 3x3</span>
    <span class="c1"># Convolution is followed by max-pooling layer with a 2x2 window</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Second convolution extracts 32 filters that are 3x3</span>
    <span class="c1"># Convolution is followed by max-pooling layer with a 2x2 window</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Third convolution extracts 64 filters that are 3x3</span>
    <span class="c1"># Convolution is followed by max-pooling layer with a 2x2 window</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Fourth convolution extracts 64 filters that are 3x3</span>
    <span class="c1"># Convolution is followed by max-pooling layer with a 2x2 window</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Flatten feature map to a 1-dim tensor so we can add fully connected layers</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Create a fully connected layer with ReLU activation and 512 hidden units</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Create output layer with a single node and sigmoid activation</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Create model:</span>
    <span class="c1"># input = input feature map</span>
    <span class="c1"># output = input feature map + stacked convolution/maxpooling layers + fully </span>
    <span class="c1"># connected layer + sigmoid output layer</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="c1"># Compile model for binary classification</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">random_model</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
      <span class="n">train_generator</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
      <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span>
      <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">history</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 150, 150, 3)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 148, 148, 16)      448       
_________________________________________________________________
activation (Activation)      (None, 148, 148, 16)      0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         
_________________________________________________________________
dropout (Dropout)            (None, 74, 74, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      
_________________________________________________________________
activation_1 (Activation)    (None, 72, 72, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 36, 36, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     
_________________________________________________________________
activation_2 (Activation)    (None, 34, 34, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 17, 17, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     
_________________________________________________________________
activation_3 (Activation)    (None, 15, 15, 64)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense (Dense)                (None, 512)               1606144   
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 1,667,169
Trainable params: 1,667,169
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/30
32/32 [==============================] - 9s 262ms/step - loss: 0.7141 - binary_accuracy: 0.5099 - val_loss: 0.6920 - val_binary_accuracy: 0.5000
Epoch 2/30
32/32 [==============================] - 8s 256ms/step - loss: 0.6934 - binary_accuracy: 0.4905 - val_loss: 0.6897 - val_binary_accuracy: 0.5260
Epoch 3/30
32/32 [==============================] - 8s 256ms/step - loss: 0.6920 - binary_accuracy: 0.5120 - val_loss: 0.6801 - val_binary_accuracy: 0.5800
Epoch 4/30
32/32 [==============================] - 8s 254ms/step - loss: 0.6733 - binary_accuracy: 0.5703 - val_loss: 0.6732 - val_binary_accuracy: 0.6220
Epoch 5/30
32/32 [==============================] - 8s 253ms/step - loss: 0.6502 - binary_accuracy: 0.6026 - val_loss: 0.6654 - val_binary_accuracy: 0.5830
Epoch 6/30
32/32 [==============================] - 8s 260ms/step - loss: 0.6307 - binary_accuracy: 0.6210 - val_loss: 0.6116 - val_binary_accuracy: 0.6610
Epoch 7/30
32/32 [==============================] - 8s 258ms/step - loss: 0.6111 - binary_accuracy: 0.6520 - val_loss: 0.5979 - val_binary_accuracy: 0.6570
Epoch 8/30
32/32 [==============================] - 8s 259ms/step - loss: 0.5801 - binary_accuracy: 0.6909 - val_loss: 0.6165 - val_binary_accuracy: 0.6370
Epoch 9/30
32/32 [==============================] - 8s 260ms/step - loss: 0.5634 - binary_accuracy: 0.6964 - val_loss: 0.6568 - val_binary_accuracy: 0.6350
Epoch 10/30
32/32 [==============================] - 8s 257ms/step - loss: 0.5374 - binary_accuracy: 0.7210 - val_loss: 0.5959 - val_binary_accuracy: 0.6740
Epoch 11/30
32/32 [==============================] - 8s 255ms/step - loss: 0.5299 - binary_accuracy: 0.7442 - val_loss: 0.5820 - val_binary_accuracy: 0.6770
Epoch 12/30
32/32 [==============================] - 8s 251ms/step - loss: 0.5058 - binary_accuracy: 0.7666 - val_loss: 0.5617 - val_binary_accuracy: 0.6970
Epoch 13/30
32/32 [==============================] - 8s 251ms/step - loss: 0.4700 - binary_accuracy: 0.7775 - val_loss: 0.5496 - val_binary_accuracy: 0.7080
Epoch 14/30
32/32 [==============================] - 8s 257ms/step - loss: 0.4492 - binary_accuracy: 0.7870 - val_loss: 0.5494 - val_binary_accuracy: 0.7190
Epoch 15/30
32/32 [==============================] - 8s 258ms/step - loss: 0.4510 - binary_accuracy: 0.7875 - val_loss: 0.6474 - val_binary_accuracy: 0.6570
Epoch 16/30
32/32 [==============================] - 8s 263ms/step - loss: 0.4638 - binary_accuracy: 0.7801 - val_loss: 0.5552 - val_binary_accuracy: 0.7200
Epoch 17/30
32/32 [==============================] - 8s 259ms/step - loss: 0.4102 - binary_accuracy: 0.8162 - val_loss: 0.5578 - val_binary_accuracy: 0.7260
Epoch 18/30
32/32 [==============================] - 8s 254ms/step - loss: 0.3905 - binary_accuracy: 0.8200 - val_loss: 0.5964 - val_binary_accuracy: 0.6960
Epoch 19/30
32/32 [==============================] - 8s 258ms/step - loss: 0.3933 - binary_accuracy: 0.8119 - val_loss: 0.5653 - val_binary_accuracy: 0.7170
Epoch 20/30
32/32 [==============================] - 8s 253ms/step - loss: 0.3423 - binary_accuracy: 0.8450 - val_loss: 0.5695 - val_binary_accuracy: 0.7100
Epoch 21/30
32/32 [==============================] - 8s 253ms/step - loss: 0.3431 - binary_accuracy: 0.8500 - val_loss: 0.5265 - val_binary_accuracy: 0.7440
Epoch 22/30
32/32 [==============================] - 8s 253ms/step - loss: 0.3214 - binary_accuracy: 0.8596 - val_loss: 0.5581 - val_binary_accuracy: 0.7470
Epoch 23/30
32/32 [==============================] - 8s 256ms/step - loss: 0.2685 - binary_accuracy: 0.8916 - val_loss: 0.5756 - val_binary_accuracy: 0.7330
Epoch 24/30
32/32 [==============================] - 8s 256ms/step - loss: 0.2530 - binary_accuracy: 0.8955 - val_loss: 0.6087 - val_binary_accuracy: 0.7340
Epoch 25/30
32/32 [==============================] - 8s 256ms/step - loss: 0.2462 - binary_accuracy: 0.9023 - val_loss: 0.5863 - val_binary_accuracy: 0.7470
Epoch 26/30
32/32 [==============================] - 8s 258ms/step - loss: 0.2188 - binary_accuracy: 0.9157 - val_loss: 0.6247 - val_binary_accuracy: 0.7340
Epoch 27/30
32/32 [==============================] - 8s 255ms/step - loss: 0.2246 - binary_accuracy: 0.9112 - val_loss: 0.5880 - val_binary_accuracy: 0.7390
Epoch 28/30
32/32 [==============================] - 8s 255ms/step - loss: 0.1869 - binary_accuracy: 0.9302 - val_loss: 0.6546 - val_binary_accuracy: 0.7360
Epoch 29/30
32/32 [==============================] - 8s 259ms/step - loss: 0.1670 - binary_accuracy: 0.9351 - val_loss: 0.6451 - val_binary_accuracy: 0.7340
Epoch 30/30
32/32 [==============================] - 8s 257ms/step - loss: 0.1181 - binary_accuracy: 0.9592 - val_loss: 0.7888 - val_binary_accuracy: 0.7400
</pre></div>
</div>
<img alt="../_images/11-TransferLearning-solution_17_1.png" src="../_images/11-TransferLearning-solution_17_1.png" />
</div>
</div>
<p><strong>A:</strong> There is no unique solution, but it is very difficult to avoid overfitting with such a low amount of data. The validation accuracy saturates between 70% and 75% while the training accuracy reaches 100% if you train for more epochs.</p>
</div>
<div class="section" id="data-augmentation">
<h2><span class="section-number">11.2.4. </span>Data augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h2>
<p>The 2000 training images will never be enough to train a CNN from scratch without overfitting, no matter how much regularization you use. A first trick that may help is <strong>data augmentation</strong>, i.e. to artificially create variations of each training image (translation, rotation, scaling, flipping, etc) while preserving the class of the images (a cat stays a cat after rotating the image).</p>
<p><code class="docutils literal notranslate"><span class="pre">ImageDataGenerator</span></code> allows to automatically apply various transformations when retrieving a minibatch (beware, it can be slow).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span>
    <span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
    <span class="n">rotation_range</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">zoom_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Refer the doc for the meaning of the parameters.</p>
<p>To investigate the transformations, let’s apply them on a single image, for example the first cat of the training set:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="s1">&#39;/tmp/cats_and_dogs_filtered/train/cats/cat.0.jpg&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>We can pass this image to the data generator and retrieve minibatches of augmented images:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Q:</strong> Display various augmented images. Vary the parameters individually by setting all but one to their default value in order to understand their effect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span>
    <span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
    <span class="n">rotation_range</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">zoom_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span>
<span class="p">)</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="s1">&#39;/tmp/cats_and_dogs_filtered/train/cats/cat.0.jpg&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">test_generator</span> <span class="o">=</span> <span class="n">test_datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">test_generator</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;Off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">augmented</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;Off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Augmented&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/11-TransferLearning-solution_20_0.png" src="../_images/11-TransferLearning-solution_20_0.png" />
<img alt="../_images/11-TransferLearning-solution_20_1.png" src="../_images/11-TransferLearning-solution_20_1.png" />
</div>
</div>
<p><strong>Q:</strong> Create an augmented training set using the parameters defined in the previous question (feel free to experiment, but that can cost time). Leave the validation generator without data augmentation (only <code class="docutils literal notranslate"><span class="pre">rescale=1./255</span></code>). Train the exact same network as before on this augmented data. What happens? You may need to train much longer in order to see the effect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data augmentation</span>
<span class="n">augmented_train_datagen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span>
    <span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span>
    <span class="n">rotation_range</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">zoom_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fill_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span>
<span class="p">)</span>

<span class="c1"># Flow training images in batches of 20 using train_datagen generator</span>
<span class="n">augmented_train_generator</span> <span class="o">=</span> <span class="n">augmented_train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="n">train_dir</span><span class="p">,</span> 
        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>  
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 2000 images belonging to 2 classes.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">random_model</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
      <span class="n">augmented_train_generator</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
      <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span>
      <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">history</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 150, 150, 3)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 148, 148, 16)      448       
_________________________________________________________________
activation (Activation)      (None, 148, 148, 16)      0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         
_________________________________________________________________
dropout (Dropout)            (None, 74, 74, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      
_________________________________________________________________
activation_1 (Activation)    (None, 72, 72, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 36, 36, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     
_________________________________________________________________
activation_2 (Activation)    (None, 34, 34, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 17, 17, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     
_________________________________________________________________
activation_3 (Activation)    (None, 15, 15, 64)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense (Dense)                (None, 512)               1606144   
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 1,667,169
Trainable params: 1,667,169
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
32/32 [==============================] - 17s 524ms/step - loss: 0.8262 - binary_accuracy: 0.4808 - val_loss: 0.6927 - val_binary_accuracy: 0.5000
Epoch 2/100
32/32 [==============================] - 16s 515ms/step - loss: 0.6950 - binary_accuracy: 0.4800 - val_loss: 0.6928 - val_binary_accuracy: 0.5360
Epoch 3/100
32/32 [==============================] - 17s 518ms/step - loss: 0.6925 - binary_accuracy: 0.5351 - val_loss: 0.6929 - val_binary_accuracy: 0.4920
Epoch 4/100
32/32 [==============================] - 16s 517ms/step - loss: 0.6933 - binary_accuracy: 0.5100 - val_loss: 0.6926 - val_binary_accuracy: 0.5440
Epoch 5/100
32/32 [==============================] - 17s 518ms/step - loss: 0.6919 - binary_accuracy: 0.5177 - val_loss: 0.6913 - val_binary_accuracy: 0.5220
Epoch 6/100
32/32 [==============================] - 17s 520ms/step - loss: 0.6915 - binary_accuracy: 0.5142 - val_loss: 0.6895 - val_binary_accuracy: 0.5410
Epoch 7/100
32/32 [==============================] - 17s 524ms/step - loss: 0.6912 - binary_accuracy: 0.5320 - val_loss: 0.6905 - val_binary_accuracy: 0.5620
Epoch 8/100
32/32 [==============================] - 17s 527ms/step - loss: 0.6899 - binary_accuracy: 0.5396 - val_loss: 0.6872 - val_binary_accuracy: 0.5220
Epoch 9/100
32/32 [==============================] - 17s 521ms/step - loss: 0.6921 - binary_accuracy: 0.5046 - val_loss: 0.6823 - val_binary_accuracy: 0.5670
Epoch 10/100
32/32 [==============================] - 17s 524ms/step - loss: 0.6842 - binary_accuracy: 0.5607 - val_loss: 0.6805 - val_binary_accuracy: 0.5870
Epoch 11/100
32/32 [==============================] - 17s 522ms/step - loss: 0.6821 - binary_accuracy: 0.5400 - val_loss: 0.6804 - val_binary_accuracy: 0.5920
Epoch 12/100
32/32 [==============================] - 17s 534ms/step - loss: 0.6771 - binary_accuracy: 0.5853 - val_loss: 0.6729 - val_binary_accuracy: 0.6220
Epoch 13/100
32/32 [==============================] - 17s 521ms/step - loss: 0.6686 - binary_accuracy: 0.5989 - val_loss: 0.6457 - val_binary_accuracy: 0.5990
Epoch 14/100
32/32 [==============================] - 17s 521ms/step - loss: 0.6508 - binary_accuracy: 0.6179 - val_loss: 0.6542 - val_binary_accuracy: 0.6280
Epoch 15/100
32/32 [==============================] - 17s 523ms/step - loss: 0.6592 - binary_accuracy: 0.5950 - val_loss: 0.6311 - val_binary_accuracy: 0.6170
Epoch 16/100
32/32 [==============================] - 17s 525ms/step - loss: 0.6434 - binary_accuracy: 0.6112 - val_loss: 0.6159 - val_binary_accuracy: 0.6510
Epoch 17/100
32/32 [==============================] - 17s 528ms/step - loss: 0.6233 - binary_accuracy: 0.6438 - val_loss: 0.6227 - val_binary_accuracy: 0.6520
Epoch 18/100
32/32 [==============================] - 17s 528ms/step - loss: 0.6171 - binary_accuracy: 0.6444 - val_loss: 0.6611 - val_binary_accuracy: 0.6080
Epoch 19/100
32/32 [==============================] - 17s 526ms/step - loss: 0.6034 - binary_accuracy: 0.6728 - val_loss: 0.6031 - val_binary_accuracy: 0.6420
Epoch 20/100
32/32 [==============================] - 17s 529ms/step - loss: 0.6099 - binary_accuracy: 0.6734 - val_loss: 0.6381 - val_binary_accuracy: 0.6200
Epoch 21/100
32/32 [==============================] - 17s 528ms/step - loss: 0.6217 - binary_accuracy: 0.6359 - val_loss: 0.5978 - val_binary_accuracy: 0.6730
Epoch 22/100
32/32 [==============================] - 17s 532ms/step - loss: 0.6067 - binary_accuracy: 0.6599 - val_loss: 0.6073 - val_binary_accuracy: 0.6430
Epoch 23/100
32/32 [==============================] - 17s 527ms/step - loss: 0.5838 - binary_accuracy: 0.6853 - val_loss: 0.6217 - val_binary_accuracy: 0.6350
Epoch 24/100
32/32 [==============================] - 17s 525ms/step - loss: 0.6003 - binary_accuracy: 0.6703 - val_loss: 0.5718 - val_binary_accuracy: 0.6710
Epoch 25/100
32/32 [==============================] - 17s 529ms/step - loss: 0.5955 - binary_accuracy: 0.6906 - val_loss: 0.5882 - val_binary_accuracy: 0.6710
Epoch 26/100
32/32 [==============================] - 17s 521ms/step - loss: 0.5729 - binary_accuracy: 0.6858 - val_loss: 0.6025 - val_binary_accuracy: 0.6420
Epoch 27/100
32/32 [==============================] - 17s 532ms/step - loss: 0.5778 - binary_accuracy: 0.6933 - val_loss: 0.6403 - val_binary_accuracy: 0.6400
Epoch 28/100
32/32 [==============================] - 17s 526ms/step - loss: 0.5750 - binary_accuracy: 0.7028 - val_loss: 0.5868 - val_binary_accuracy: 0.6580
Epoch 29/100
32/32 [==============================] - 17s 524ms/step - loss: 0.5561 - binary_accuracy: 0.7097 - val_loss: 0.5700 - val_binary_accuracy: 0.6850
Epoch 30/100
32/32 [==============================] - 17s 528ms/step - loss: 0.5700 - binary_accuracy: 0.7154 - val_loss: 0.5680 - val_binary_accuracy: 0.6850
Epoch 31/100
32/32 [==============================] - 17s 527ms/step - loss: 0.5549 - binary_accuracy: 0.7259 - val_loss: 0.5861 - val_binary_accuracy: 0.6600
Epoch 32/100
32/32 [==============================] - 17s 525ms/step - loss: 0.5540 - binary_accuracy: 0.7203 - val_loss: 0.6122 - val_binary_accuracy: 0.6490
Epoch 33/100
32/32 [==============================] - 17s 517ms/step - loss: 0.5456 - binary_accuracy: 0.7299 - val_loss: 0.5736 - val_binary_accuracy: 0.6760
Epoch 34/100
32/32 [==============================] - 16s 513ms/step - loss: 0.5588 - binary_accuracy: 0.7088 - val_loss: 0.5642 - val_binary_accuracy: 0.6980
Epoch 35/100
32/32 [==============================] - 16s 515ms/step - loss: 0.5556 - binary_accuracy: 0.7112 - val_loss: 0.5556 - val_binary_accuracy: 0.6960
Epoch 36/100
32/32 [==============================] - 17s 519ms/step - loss: 0.5591 - binary_accuracy: 0.7224 - val_loss: 0.5526 - val_binary_accuracy: 0.6960
Epoch 37/100
32/32 [==============================] - 17s 521ms/step - loss: 0.5377 - binary_accuracy: 0.7079 - val_loss: 0.5578 - val_binary_accuracy: 0.6920
Epoch 38/100
32/32 [==============================] - 17s 541ms/step - loss: 0.5404 - binary_accuracy: 0.7196 - val_loss: 0.5525 - val_binary_accuracy: 0.7000
Epoch 39/100
32/32 [==============================] - 17s 537ms/step - loss: 0.5479 - binary_accuracy: 0.7089 - val_loss: 0.5278 - val_binary_accuracy: 0.7270
Epoch 40/100
32/32 [==============================] - 17s 545ms/step - loss: 0.5275 - binary_accuracy: 0.7281 - val_loss: 0.5421 - val_binary_accuracy: 0.7160
Epoch 41/100
32/32 [==============================] - 17s 527ms/step - loss: 0.5375 - binary_accuracy: 0.7202 - val_loss: 0.5675 - val_binary_accuracy: 0.6810
Epoch 42/100
32/32 [==============================] - 17s 527ms/step - loss: 0.5166 - binary_accuracy: 0.7498 - val_loss: 0.5210 - val_binary_accuracy: 0.7430
Epoch 43/100
32/32 [==============================] - 17s 529ms/step - loss: 0.5361 - binary_accuracy: 0.7237 - val_loss: 0.5305 - val_binary_accuracy: 0.7300
Epoch 44/100
32/32 [==============================] - 17s 530ms/step - loss: 0.5306 - binary_accuracy: 0.7395 - val_loss: 0.5289 - val_binary_accuracy: 0.7240
Epoch 45/100
32/32 [==============================] - 17s 529ms/step - loss: 0.5587 - binary_accuracy: 0.7214 - val_loss: 0.5584 - val_binary_accuracy: 0.6970
Epoch 46/100
32/32 [==============================] - 17s 530ms/step - loss: 0.5125 - binary_accuracy: 0.7593 - val_loss: 0.5626 - val_binary_accuracy: 0.7060
Epoch 47/100
32/32 [==============================] - 17s 527ms/step - loss: 0.5197 - binary_accuracy: 0.7342 - val_loss: 0.5397 - val_binary_accuracy: 0.7160
Epoch 48/100
32/32 [==============================] - 17s 528ms/step - loss: 0.5093 - binary_accuracy: 0.7512 - val_loss: 0.5002 - val_binary_accuracy: 0.7490
Epoch 49/100
32/32 [==============================] - 17s 536ms/step - loss: 0.5141 - binary_accuracy: 0.7506 - val_loss: 0.5185 - val_binary_accuracy: 0.7460
Epoch 50/100
32/32 [==============================] - 17s 526ms/step - loss: 0.5214 - binary_accuracy: 0.7376 - val_loss: 0.5193 - val_binary_accuracy: 0.7300
Epoch 51/100
32/32 [==============================] - 17s 534ms/step - loss: 0.4966 - binary_accuracy: 0.7579 - val_loss: 0.4980 - val_binary_accuracy: 0.7450
Epoch 52/100
32/32 [==============================] - 17s 532ms/step - loss: 0.4921 - binary_accuracy: 0.7616 - val_loss: 0.5075 - val_binary_accuracy: 0.7530
Epoch 53/100
32/32 [==============================] - 17s 533ms/step - loss: 0.4879 - binary_accuracy: 0.7747 - val_loss: 0.5018 - val_binary_accuracy: 0.7550
Epoch 54/100
32/32 [==============================] - 17s 530ms/step - loss: 0.5003 - binary_accuracy: 0.7635 - val_loss: 0.4956 - val_binary_accuracy: 0.7430
Epoch 55/100
32/32 [==============================] - 17s 535ms/step - loss: 0.5102 - binary_accuracy: 0.7483 - val_loss: 0.5061 - val_binary_accuracy: 0.7560
Epoch 56/100
32/32 [==============================] - 17s 536ms/step - loss: 0.5002 - binary_accuracy: 0.7568 - val_loss: 0.4971 - val_binary_accuracy: 0.7600
Epoch 57/100
32/32 [==============================] - 17s 533ms/step - loss: 0.4868 - binary_accuracy: 0.7538 - val_loss: 0.5062 - val_binary_accuracy: 0.7420
Epoch 58/100
32/32 [==============================] - 17s 536ms/step - loss: 0.5103 - binary_accuracy: 0.7462 - val_loss: 0.5032 - val_binary_accuracy: 0.7570
Epoch 59/100
32/32 [==============================] - 17s 535ms/step - loss: 0.4881 - binary_accuracy: 0.7745 - val_loss: 0.4928 - val_binary_accuracy: 0.7540
Epoch 60/100
32/32 [==============================] - 17s 539ms/step - loss: 0.4862 - binary_accuracy: 0.7616 - val_loss: 0.4872 - val_binary_accuracy: 0.7630
Epoch 61/100
32/32 [==============================] - 17s 537ms/step - loss: 0.4884 - binary_accuracy: 0.7673 - val_loss: 0.5324 - val_binary_accuracy: 0.7250
Epoch 62/100
32/32 [==============================] - 17s 536ms/step - loss: 0.5056 - binary_accuracy: 0.7596 - val_loss: 0.5036 - val_binary_accuracy: 0.7400
Epoch 63/100
32/32 [==============================] - 17s 533ms/step - loss: 0.5182 - binary_accuracy: 0.7338 - val_loss: 0.4898 - val_binary_accuracy: 0.7540
Epoch 64/100
32/32 [==============================] - 17s 532ms/step - loss: 0.4798 - binary_accuracy: 0.7658 - val_loss: 0.5131 - val_binary_accuracy: 0.7310
Epoch 65/100
32/32 [==============================] - 17s 533ms/step - loss: 0.4742 - binary_accuracy: 0.7762 - val_loss: 0.5140 - val_binary_accuracy: 0.7300
Epoch 66/100
32/32 [==============================] - 17s 534ms/step - loss: 0.4807 - binary_accuracy: 0.7742 - val_loss: 0.5039 - val_binary_accuracy: 0.7450
Epoch 67/100
32/32 [==============================] - 17s 539ms/step - loss: 0.4677 - binary_accuracy: 0.7741 - val_loss: 0.4979 - val_binary_accuracy: 0.7450
Epoch 68/100
32/32 [==============================] - 17s 530ms/step - loss: 0.4581 - binary_accuracy: 0.7748 - val_loss: 0.4754 - val_binary_accuracy: 0.7690
Epoch 69/100
32/32 [==============================] - 17s 535ms/step - loss: 0.4514 - binary_accuracy: 0.7823 - val_loss: 0.4992 - val_binary_accuracy: 0.7370
Epoch 70/100
32/32 [==============================] - 17s 537ms/step - loss: 0.4372 - binary_accuracy: 0.7907 - val_loss: 0.5032 - val_binary_accuracy: 0.7540
Epoch 71/100
32/32 [==============================] - 17s 537ms/step - loss: 0.4563 - binary_accuracy: 0.7792 - val_loss: 0.4846 - val_binary_accuracy: 0.7530
Epoch 72/100
32/32 [==============================] - 17s 537ms/step - loss: 0.4867 - binary_accuracy: 0.7539 - val_loss: 0.4752 - val_binary_accuracy: 0.7680
Epoch 73/100
32/32 [==============================] - 17s 539ms/step - loss: 0.4437 - binary_accuracy: 0.7968 - val_loss: 0.4952 - val_binary_accuracy: 0.7480
Epoch 74/100
32/32 [==============================] - 17s 544ms/step - loss: 0.4775 - binary_accuracy: 0.7698 - val_loss: 0.4987 - val_binary_accuracy: 0.7520
Epoch 75/100
32/32 [==============================] - 17s 534ms/step - loss: 0.4443 - binary_accuracy: 0.7975 - val_loss: 0.4757 - val_binary_accuracy: 0.7610
Epoch 76/100
32/32 [==============================] - 17s 531ms/step - loss: 0.4534 - binary_accuracy: 0.7972 - val_loss: 0.4805 - val_binary_accuracy: 0.7690
Epoch 77/100
32/32 [==============================] - 17s 535ms/step - loss: 0.4586 - binary_accuracy: 0.7817 - val_loss: 0.4746 - val_binary_accuracy: 0.7660
Epoch 78/100
32/32 [==============================] - 17s 532ms/step - loss: 0.4620 - binary_accuracy: 0.7785 - val_loss: 0.4742 - val_binary_accuracy: 0.7710
Epoch 79/100
32/32 [==============================] - 17s 538ms/step - loss: 0.4550 - binary_accuracy: 0.7775 - val_loss: 0.4821 - val_binary_accuracy: 0.7600
Epoch 80/100
32/32 [==============================] - 17s 533ms/step - loss: 0.4347 - binary_accuracy: 0.7932 - val_loss: 0.4802 - val_binary_accuracy: 0.7700
Epoch 81/100
32/32 [==============================] - 17s 534ms/step - loss: 0.4382 - binary_accuracy: 0.7988 - val_loss: 0.4894 - val_binary_accuracy: 0.7620
Epoch 82/100
32/32 [==============================] - 17s 530ms/step - loss: 0.4452 - binary_accuracy: 0.7877 - val_loss: 0.4647 - val_binary_accuracy: 0.7740
Epoch 83/100
32/32 [==============================] - 17s 536ms/step - loss: 0.4346 - binary_accuracy: 0.8014 - val_loss: 0.4760 - val_binary_accuracy: 0.7680
Epoch 84/100
32/32 [==============================] - 17s 542ms/step - loss: 0.4560 - binary_accuracy: 0.7894 - val_loss: 0.4835 - val_binary_accuracy: 0.7530
Epoch 85/100
32/32 [==============================] - 17s 544ms/step - loss: 0.4110 - binary_accuracy: 0.8134 - val_loss: 0.4724 - val_binary_accuracy: 0.7660
Epoch 86/100
32/32 [==============================] - 17s 541ms/step - loss: 0.4253 - binary_accuracy: 0.8130 - val_loss: 0.4585 - val_binary_accuracy: 0.7700
Epoch 87/100
32/32 [==============================] - 17s 535ms/step - loss: 0.4038 - binary_accuracy: 0.8123 - val_loss: 0.4731 - val_binary_accuracy: 0.7620
Epoch 88/100
32/32 [==============================] - 17s 541ms/step - loss: 0.4446 - binary_accuracy: 0.7898 - val_loss: 0.4692 - val_binary_accuracy: 0.7660
Epoch 89/100
32/32 [==============================] - 17s 536ms/step - loss: 0.4446 - binary_accuracy: 0.7914 - val_loss: 0.4683 - val_binary_accuracy: 0.7880
Epoch 90/100
32/32 [==============================] - 17s 533ms/step - loss: 0.4360 - binary_accuracy: 0.7955 - val_loss: 0.4592 - val_binary_accuracy: 0.7720
Epoch 91/100
32/32 [==============================] - 17s 544ms/step - loss: 0.4439 - binary_accuracy: 0.7940 - val_loss: 0.5066 - val_binary_accuracy: 0.7500
Epoch 92/100
32/32 [==============================] - 17s 531ms/step - loss: 0.4176 - binary_accuracy: 0.7898 - val_loss: 0.4410 - val_binary_accuracy: 0.7900
Epoch 93/100
32/32 [==============================] - 17s 536ms/step - loss: 0.4172 - binary_accuracy: 0.8100 - val_loss: 0.4709 - val_binary_accuracy: 0.7690
Epoch 94/100
32/32 [==============================] - 17s 533ms/step - loss: 0.3971 - binary_accuracy: 0.8146 - val_loss: 0.4610 - val_binary_accuracy: 0.7670
Epoch 95/100
32/32 [==============================] - 17s 531ms/step - loss: 0.3782 - binary_accuracy: 0.8344 - val_loss: 0.4652 - val_binary_accuracy: 0.7710
Epoch 96/100
32/32 [==============================] - 17s 537ms/step - loss: 0.3920 - binary_accuracy: 0.8257 - val_loss: 0.4620 - val_binary_accuracy: 0.7660
Epoch 97/100
32/32 [==============================] - 17s 537ms/step - loss: 0.4244 - binary_accuracy: 0.7992 - val_loss: 0.5328 - val_binary_accuracy: 0.7350
Epoch 98/100
32/32 [==============================] - 17s 539ms/step - loss: 0.4222 - binary_accuracy: 0.8125 - val_loss: 0.4635 - val_binary_accuracy: 0.7750
Epoch 99/100
32/32 [==============================] - 17s 538ms/step - loss: 0.3942 - binary_accuracy: 0.8214 - val_loss: 0.4468 - val_binary_accuracy: 0.7830
Epoch 100/100
32/32 [==============================] - 17s 538ms/step - loss: 0.3979 - binary_accuracy: 0.8131 - val_loss: 0.4501 - val_binary_accuracy: 0.7820
</pre></div>
</div>
<img alt="../_images/11-TransferLearning-solution_23_1.png" src="../_images/11-TransferLearning-solution_23_1.png" />
</div>
</div>
<p><strong>A:</strong> Data augmentation prevents overfitting, as the network never sees twice the same image. Learning is much slower, but it can bring the validation accuracy significantly higher (80% after 100 epochs).</p>
</div>
<div class="section" id="id1">
<h2><span class="section-number">11.2.5. </span>Transfer learning<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Data augmentation helps randomly initialized to learn from small datasets, but the best solution is to start training with already good weights.</p>
<p><strong>Transfer learning</strong> allows to reuse the weights of a CNN trained on a bigger dataset (e.g. ImageNet) to either extract features for a shallow classifier or to allow fine-tuning of all weights.</p>
<p>Keras provides a considerable number of pre-trained CNNs:</p>
<p><a class="reference external" href="https://keras.io/api/applications/">https://keras.io/api/applications/</a></p>
<p>In this exercise, we will use the Xception network for feature extraction, but feel free to experiment with other architectures. To download the weights and create the keras model, simply call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xception</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">Xception</span><span class="p">(</span>
        <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>  <span class="c1"># Load weights pre-trained on ImageNet.</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="c1"># Input shape</span>
        <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># Only the convolutional layers, not the last fully-connected ones</span>
    <span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">include_top=False</span></code> removes the last fully-connected layers used to predict the ImageNet classes, as we only care about the binary cat/dog classification.</p>
<p><strong>Q:</strong> Download Xception and print its summary. Make sense of the various layers (the paper might help: <a class="reference external" href="http://arxiv.org/abs/1610.02357">http://arxiv.org/abs/1610.02357</a>). What is the size of the final tensor?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="n">xception</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">Xception</span><span class="p">(</span>
        <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>  <span class="c1"># Load weights pre-trained on ImageNet.</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="c1"># Input shape</span>
        <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># Only the convolutional layers, not the last fully-connected ones</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">xception</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;xception&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 36, 36, 128)  512         conv2d[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 36, 36, 128)  0           block2_pool[0][0]                
                                                                 batch_normalization[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add[0][0]                        
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 18, 18, 256)  32768       add[0][0]                        
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 18, 18, 256)  1024        conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_1[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 9, 9, 728)    186368      add_1[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 9, 9, 728)    2912        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_2[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 5, 5, 1024)   745472      add_10[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 5, 5, 1024)   4096        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_11 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_11[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           
__________________________________________________________________________________________________
block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        
==================================================================================================
Total params: 20,861,480
Trainable params: 20,806,952
Non-trainable params: 54,528
__________________________________________________________________________________________________
None
</pre></div>
</div>
</div>
</div>
<p>Let’s now use transfer learning using this network. The first thing to do is to freeze Xception to make sure that it does learn from the cats and dogs data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">xception</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>We can then connect Xception to the inputs, making sure again that the network won’t learn (in particular, the parameters of batch normalization are kept):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">xception</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now use the layer <code class="docutils literal notranslate"><span class="pre">x</span></code> and stack what we want on top of it. Instead of flattening the 5x5x2048 tensor, it is usually better to apply <strong>average-pooling</strong> (or mean-pooling) on each 5x5 feature map to obtain a vector with 2048 elements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Q:</strong> Perform a soft linear classification on this vector with 2048 elements to recognize cats from dogs (using non-augmented data). Do not hesitate to use some dropout and to boost your learning rate, there are only 2049 trainable parameters. Conclude.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_model</span><span class="p">():</span>

    <span class="c1"># Delete all previous models to free memory</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

    <span class="c1"># Use Xception as a feature extractor</span>
    <span class="n">xception</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">Xception</span><span class="p">(</span>
        <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>  <span class="c1"># Load weights pre-trained on ImageNet.</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="c1"># Input shape</span>
        <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># Only the convolutional layers, not the last fully-connected ones</span>
    <span class="p">)</span>  <span class="c1"># Do not include the ImageNet classifier at the top.</span>

    <span class="c1"># Freeze the base model</span>
    <span class="n">xception</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Create new model on top</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="c1"># The base model contains batchnorm layers. We want to keep them in inference mode</span>
    <span class="c1"># when we unfreeze the base model for fine-tuning, so we make sure that the</span>
    <span class="c1"># base_model is running in inference mode here.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xception</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># GlobalAveragePooling2D applies average-pooling on each 5x5 feature map</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Regularize with dropout</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  

    <span class="c1"># Output layer for binary classification</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">],</span>
    <span class="p">)</span>


    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">transfer_model</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
      <span class="n">train_generator</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
      <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span>
      <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">history</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch #&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 150, 150, 3)]     0         
_________________________________________________________________
xception (Functional)        (None, 5, 5, 2048)        20861480  
_________________________________________________________________
global_average_pooling2d (Gl (None, 2048)              0         
_________________________________________________________________
dropout (Dropout)            (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 1)                 2049      
=================================================================
Total params: 20,863,529
Trainable params: 2,049
Non-trainable params: 20,861,480
_________________________________________________________________
None
Epoch 1/10
32/32 [==============================] - 15s 360ms/step - loss: 3.4920 - binary_accuracy: 0.6595 - val_loss: 0.7931 - val_binary_accuracy: 0.9070
Epoch 2/10
32/32 [==============================] - 10s 319ms/step - loss: 1.2681 - binary_accuracy: 0.8763 - val_loss: 1.3583 - val_binary_accuracy: 0.8750
Epoch 3/10
32/32 [==============================] - 10s 318ms/step - loss: 1.1298 - binary_accuracy: 0.8965 - val_loss: 0.5870 - val_binary_accuracy: 0.9320
Epoch 4/10
32/32 [==============================] - 10s 318ms/step - loss: 0.9257 - binary_accuracy: 0.9131 - val_loss: 0.5385 - val_binary_accuracy: 0.9420
Epoch 5/10
32/32 [==============================] - 10s 322ms/step - loss: 0.8005 - binary_accuracy: 0.9210 - val_loss: 0.4932 - val_binary_accuracy: 0.9430
Epoch 6/10
32/32 [==============================] - 10s 317ms/step - loss: 1.1902 - binary_accuracy: 0.8863 - val_loss: 0.5832 - val_binary_accuracy: 0.9410
Epoch 7/10
32/32 [==============================] - 10s 314ms/step - loss: 0.7802 - binary_accuracy: 0.9168 - val_loss: 0.5809 - val_binary_accuracy: 0.9390
Epoch 8/10
32/32 [==============================] - 10s 315ms/step - loss: 0.7507 - binary_accuracy: 0.9236 - val_loss: 0.5680 - val_binary_accuracy: 0.9400
Epoch 9/10
32/32 [==============================] - 10s 315ms/step - loss: 0.6364 - binary_accuracy: 0.9321 - val_loss: 0.6099 - val_binary_accuracy: 0.9420
Epoch 10/10
32/32 [==============================] - 10s 316ms/step - loss: 0.6671 - binary_accuracy: 0.9366 - val_loss: 0.5558 - val_binary_accuracy: 0.9420
</pre></div>
</div>
<img alt="../_images/11-TransferLearning-solution_29_1.png" src="../_images/11-TransferLearning-solution_29_1.png" />
</div>
</div>
<p><strong>A:</strong> Using feature extraction, we obtain very quickly a validation accuracy around 95% on the small unaugmented dataset, a performance out of reach of randomly initialized networks even with data augmentation. Conclusion: if you can use transfer learning, use it.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./5-exercises"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="11-TransferLearning.html" title="previous page"><span class="section-number">11.1. </span>Transfer learning</a>
    <a class='right-next' id="next-link" href="ex12-VAE.html" title="next page"><span class="section-number">12. </span>Variational autoencoder</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Julien Vitay - julien.vitay@informatik.tu-chemnitz.de<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            Technische Universität Chemnitz - Faculty of Computer Science - Professorship for Artificial Intelligence
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>