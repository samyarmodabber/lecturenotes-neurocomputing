
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Bibliography &#8212; Neurocomputing</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystyle.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://julien-vitay.net/lecturenotes-neurocomputing/zreferences.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="13.2. Recurrent neural networks" href="5-exercises/13-RNN-solution.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://julien-vitay.net/lecturenotes-neurocomputing/zreferences.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Bibliography" />
<meta property="og:description" content="Bibliography  Arjovsky et al., 2017  Arjovsky, M., Chintala, S., &amp; Bottou, L. (2017 , January). Wasserstein GAN. arXiv:1701.07875 [cs, stat]. URL: http://arxiv." />
<meta property="og:image"       content="https://julien-vitay.net/lecturenotes-neurocomputing/_static/tuc.svg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/tuc.svg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neurocomputing</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Neurocomputing
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="1-intro/1-Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1-intro/2-Math.html">
   2. Math basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1-intro/3-Neurons.html">
   3. Neurons
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/1-Optimization.html">
   1. Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/2-LinearRegression.html">
   2. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/3-Regularization.html">
   3. Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/4-LinearClassification.html">
   4. Linear classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/5-Multiclassification.html">
   5. Multi-class classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-linear/6-LearningTheory.html">
   6. Learning theory
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Deep learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/1-NN.html">
   1. Artificial neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/2-DNN.html">
   2. Deep neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/3-CNN.html">
   3. Convolutional neural networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/4-ObjectDetection.html">
   4. Object detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/5-SemanticSegmentation.html">
   5. Semantic segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/6-Autoencoders.html">
   6. Autoencoders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/7-RBM.html">
   7. Restricted Boltzmann machines (optional)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/8-GAN.html">
   8. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-deeplearning/9-RNN.html">
   9. Recurrent neural networks
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Neurocomputing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="4-neurocomputing/1-Limits.html">
   1. Limits of deep learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4-neurocomputing/2-Hopfield.html">
   2. Hopfield networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4-neurocomputing/4-Reservoir.html">
   3. Reservoir computing
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex1-Python.html">
   1. Introduction to Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/1-Python.html">
     1.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/1-Python-solution.html">
     1.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex2-Numpy.html">
   2. Numpy and Matplotlib
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/2-Numpy.html">
     2.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/2-Numpy-solution.html">
     2.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex3-LinearRegression.html">
   3. Linear regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/3-LinearRegression.html">
     3.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/3-LinearRegression-solution.html">
     3.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex4-MLR.html">
   4. Multiple Linear Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/4-MLR.html">
     4.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/4-MLR-solution.html">
     4.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex5-Crossvalidation.html">
   5. Cross-validation
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/5-Crossvalidation.html">
     5.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/5-Crossvalidation-solution.html">
     5.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex6-LinearClassification.html">
   6. Linear classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/6-LinearClassification.html">
     6.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/6-LinearClassification-solution.html">
     6.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex7-SoftmaxClassifier.html">
   7. Softmax classifier
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/7-SoftmaxClassifier.html">
     7.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/7-SoftmaxClassifier-solution.html">
     7.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex8-MLP.html">
   8. Multi-layer perceptron
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/8-MLP.html">
     8.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/8-MLP-solution.html">
     8.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex9-MNIST.html">
   9. MNIST classification using keras
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/9-MNIST.html">
     9.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/9-MNIST-solution.html">
     9.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex10-CNN.html">
   10. Convolutional neural networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/10-CNN.html">
     10.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/10-CNN-solution.html">
     10.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex11-TransferLearning.html">
   11. Transfer learning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/11-TransferLearning.html">
     11.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/11-TransferLearning-solution.html">
     11.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex12-VAE.html">
   12. Variational autoencoder
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/12-VAE.html">
     12.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/12-VAE-solution.html">
     12.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="5-exercises/ex13-RNN.html">
   13. Recurrent neural networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/13-RNN.html">
     13.1. Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="5-exercises/13-RNN-solution.html">
     13.2. Solution
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Bibliography
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/zreferences.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="bibliography">
<h1><span class="section-number">1. </span>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h1>
<p id="bibtex-bibliography-zreferences-0"><dl class="citation">
<dt class="bibtex label" id="arjovsky2017"><span class="brackets">Arjovsky et al., 2017</span></dt>
<dd><p>Arjovsky, M., Chintala, S., &amp; Bottou, L. (2017 , January). Wasserstein GAN. <em>arXiv:1701.07875 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1701.07875">http://arxiv.org/abs/1701.07875</a>, <a class="reference external" href="https://arxiv.org/abs/1701.07875">arXiv:1701.07875</a></p>
</dd>
<dt class="bibtex label" id="badrinarayanan2016"><span class="brackets">Badrinarayanan et al., 2016</span></dt>
<dd><p>Badrinarayanan, V., Kendall, A., &amp; Cipolla, R. (2016 , October). SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. <em>arXiv:1511.00561 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1511.00561">http://arxiv.org/abs/1511.00561</a>, <a class="reference external" href="https://arxiv.org/abs/1511.00561">arXiv:1511.00561</a></p>
</dd>
<dt class="bibtex label" id="bahdanau2016"><span class="brackets">Bahdanau et al., 2016</span></dt>
<dd><p>Bahdanau, D., Cho, K., &amp; Bengio, Y. (2016 , May). Neural Machine Translation by Jointly Learning to Align and Translate. <em>arXiv:1409.0473 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1409.0473">http://arxiv.org/abs/1409.0473</a>, <a class="reference external" href="https://arxiv.org/abs/1409.0473">arXiv:1409.0473</a></p>
</dd>
<dt class="bibtex label" id="binder2016"><span class="brackets">Binder et al., 2016</span></dt>
<dd><p>Binder, A., Montavon, G., Bach, S., Müller, K.-R., &amp; Samek, W. (2016 , April). Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers. <em>arXiv:1604.00825 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1604.00825">http://arxiv.org/abs/1604.00825</a>, <a class="reference external" href="https://arxiv.org/abs/1604.00825">arXiv:1604.00825</a></p>
</dd>
<dt class="bibtex label" id="bojarski2016"><span class="brackets">Bojarski et al., 2016</span></dt>
<dd><p>Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., … Zieba, K. (2016 , April). End to End Learning for Self-Driving Cars. <em>arXiv:1604.07316 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1604.07316">http://arxiv.org/abs/1604.07316</a>, <a class="reference external" href="https://arxiv.org/abs/1604.07316">arXiv:1604.07316</a></p>
</dd>
<dt class="bibtex label" id="brette2005"><span class="brackets">Brette &amp; Gerstner, 2005</span></dt>
<dd><p>Brette, R., &amp; Gerstner, W. (2005 , November). Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity. <em>Journal of Neurophysiology</em>, <em>94</em>(5), 3637–3642. URL: <a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.00686.2005">https://journals.physiology.org/doi/full/10.1152/jn.00686.2005</a>, <a class="reference external" href="https://doi.org/10.1152/jn.00686.2005">doi:10.1152/jn.00686.2005</a></p>
</dd>
<dt class="bibtex label" id="chollet2017a"><span class="brackets">Chollet, 2017a</span></dt>
<dd><p>Chollet, F. (2017). <em>Deep Learning with Python</em>. Manning publications.</p>
</dd>
<dt class="bibtex label" id="chollet2017b"><span class="brackets">Chollet, 2017b</span></dt>
<dd><p>Chollet, F. (2017 , April). Xception: Deep Learning with Depthwise Separable Convolutions. <em>arXiv:1610.02357 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1610.02357">http://arxiv.org/abs/1610.02357</a>, <a class="reference external" href="https://arxiv.org/abs/1610.02357">arXiv:1610.02357</a></p>
</dd>
<dt class="bibtex label" id="chung2014"><span class="brackets">Chung et al., 2014</span></dt>
<dd><p>Chung, J., Gulcehre, C., Cho, K., &amp; Bengio, Y. (2014 , December). Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. <em>arXiv:1412.3555 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1412.3555">http://arxiv.org/abs/1412.3555</a>, <a class="reference external" href="https://arxiv.org/abs/1412.3555">arXiv:1412.3555</a></p>
</dd>
<dt class="bibtex label" id="demircigil2017"><span class="brackets">Demircigil et al., 2017</span></dt>
<dd><p>Demircigil, M., Heusel, J., Löwe, M., Upgang, S., &amp; Vermet, F. (2017 , July). On a model of associative memory with huge storage capacity. <em>Journal of Statistical Physics</em>, <em>168</em>(2), 288–299. URL: <a class="reference external" href="http://arxiv.org/abs/1702.01929">http://arxiv.org/abs/1702.01929</a>, <a class="reference external" href="https://arxiv.org/abs/1702.01929">arXiv:1702.01929</a>, <a class="reference external" href="https://doi.org/10.1007/s10955-017-1806-y">doi:10.1007/s10955-017-1806-y</a></p>
</dd>
<dt class="bibtex label" id="fukushima1980"><span class="brackets">Fukushima, 1980</span></dt>
<dd><p>Fukushima, K. (1980 , April). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. <em>Biological Cybernetics</em>, <em>36</em>(4), 193–202. URL: <a class="reference external" href="https://doi.org/10.1007/BF00344251">https://doi.org/10.1007/BF00344251</a>, <a class="reference external" href="https://doi.org/10.1007/BF00344251">doi:10.1007/BF00344251</a></p>
</dd>
<dt class="bibtex label" id="gers2000"><span class="brackets">Gers &amp; Schmidhuber, 2000</span></dt>
<dd><p>Gers, F. A., &amp; Schmidhuber, J. (2000 , July). Recurrent nets that time and count. <em>Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium</em> (pp. 189–194 vol.3). <a class="reference external" href="https://doi.org/10.1109/IJCNN.2000.861302">doi:10.1109/IJCNN.2000.861302</a></p>
</dd>
<dt class="bibtex label" id="gerstner2014a"><span class="brackets">Gerstner et al., 2014</span></dt>
<dd><p>Gerstner, W., Kistler, W., Naud, R., &amp; Paninski, L. (2014). <em>Neuronal Dynamics - a Neuroscience Textbook</em>. Cambridge University Press.</p>
</dd>
<dt class="bibtex label" id="girshick2015"><span class="brackets">Girshick, 2015</span></dt>
<dd><p>Girshick, R. (2015 , September). Fast R-CNN. <em>arXiv:1504.08083 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1504.08083">http://arxiv.org/abs/1504.08083</a>, <a class="reference external" href="https://arxiv.org/abs/1504.08083">arXiv:1504.08083</a></p>
</dd>
<dt class="bibtex label" id="girshick2014"><span class="brackets">Girshick et al., 2014</span></dt>
<dd><p>Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014 , October). Rich feature hierarchies for accurate object detection and semantic segmentation. <em>arXiv:1311.2524 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1311.2524">http://arxiv.org/abs/1311.2524</a>, <a class="reference external" href="https://arxiv.org/abs/1311.2524">arXiv:1311.2524</a></p>
</dd>
<dt class="bibtex label" id="glorot2010"><span class="brackets">Glorot &amp; Bengio, 2010</span></dt>
<dd><p>Glorot, X., &amp; Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. <em>AISTATS</em> (p. 8).</p>
</dd>
<dt class="bibtex label" id="goodfellow2016"><span class="brackets">Goodfellow et al., 2016</span></dt>
<dd><p>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</p>
</dd>
<dt class="bibtex label" id="goodfellow2015"><span class="brackets">Goodfellow et al., 2015</span></dt>
<dd><p>Goodfellow, I. J., Shlens, J., &amp; Szegedy, C. (2015 , March). Explaining and Harnessing Adversarial Examples. <em>arXiv:1412.6572 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1412.6572">http://arxiv.org/abs/1412.6572</a>, <a class="reference external" href="https://arxiv.org/abs/1412.6572">arXiv:1412.6572</a></p>
</dd>
<dt class="bibtex label" id="goodfellow2014"><span class="brackets">Goodfellow et al., 2014</span></dt>
<dd><p>Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014 , June). Generative Adversarial Networks. <em>arXiv:1406.2661 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1406.2661">http://arxiv.org/abs/1406.2661</a>, <a class="reference external" href="https://arxiv.org/abs/1406.2661">arXiv:1406.2661</a></p>
</dd>
<dt class="bibtex label" id="gou2020"><span class="brackets">Gou et al., 2020</span></dt>
<dd><p>Gou, J., Yu, B., Maybank, S. J., &amp; Tao, D. (2020 , June). Knowledge Distillation: A Survey. <em>arXiv:2006.05525 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/2006.05525">http://arxiv.org/abs/2006.05525</a>, <a class="reference external" href="https://arxiv.org/abs/2006.05525">arXiv:2006.05525</a></p>
</dd>
<dt class="bibtex label" id="guo2017"><span class="brackets">Guo et al., 2017</span></dt>
<dd><p>Guo, X., Liu, X., Zhu, E., &amp; Yin, J. (2017). Liu, D., Xie, S., Li, Y., Zhao, D., &amp; El-Alfy, E.-S. M. (Eds.). Deep Clustering with Convolutional Autoencoders. <em>Neural Information Processing</em> (pp. 373–382). Cham: Springer International Publishing. <a class="reference external" href="https://doi.org/10.1007/978-3-319-70096-0_39">doi:10.1007/978-3-319-70096-0_39</a></p>
</dd>
<dt class="bibtex label" id="gupta2014"><span class="brackets">Gupta et al., 2014</span></dt>
<dd><p>Gupta, S., Girshick, R., Arbeláez, P., &amp; Malik, J. (2014 , July). Learning Rich Features from RGB-D Images for Object Detection and Segmentation. <em>arXiv:1407.5736 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1407.5736">http://arxiv.org/abs/1407.5736</a>, <a class="reference external" href="https://arxiv.org/abs/1407.5736">arXiv:1407.5736</a></p>
</dd>
<dt class="bibtex label" id="hannun2014"><span class="brackets">Hannun et al., 2014</span></dt>
<dd><p>Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., … Ng, A. Y. (2014 , December). Deep Speech: Scaling up end-to-end speech recognition. <em>arXiv:1412.5567 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1412.5567">http://arxiv.org/abs/1412.5567</a>, <a class="reference external" href="https://arxiv.org/abs/1412.5567">arXiv:1412.5567</a></p>
</dd>
<dt class="bibtex label" id="haykin2009"><span class="brackets">Haykin, 2009</span></dt>
<dd><p>Haykin, S. S. (2009). <em>Neural Networks and Learning Machines, 3rd Edition</em>. Pearson.</p>
</dd>
<dt class="bibtex label" id="he2018"><span class="brackets">He et al., 2018</span></dt>
<dd><p>He, K., Gkioxari, G., Dollár, P., &amp; Girshick, R. (2018 , January). Mask R-CNN. <em>arXiv:1703.06870 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1703.06870">http://arxiv.org/abs/1703.06870</a>, <a class="reference external" href="https://arxiv.org/abs/1703.06870">arXiv:1703.06870</a></p>
</dd>
<dt class="bibtex label" id="he2015"><span class="brackets">He et al., 2015a</span></dt>
<dd><p>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2015 , December). Deep Residual Learning for Image Recognition. <em>arXiv:1512.03385 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a>, <a class="reference external" href="https://arxiv.org/abs/1512.03385">arXiv:1512.03385</a></p>
</dd>
<dt class="bibtex label" id="he2015a"><span class="brackets">He et al., 2015b</span></dt>
<dd><p>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2015 , February). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. <em>arXiv:1502.01852 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1502.01852">http://arxiv.org/abs/1502.01852</a>, <a class="reference external" href="https://arxiv.org/abs/1502.01852">arXiv:1502.01852</a></p>
</dd>
<dt class="bibtex label" id="higgins2016"><span class="brackets">Higgins et al., 2016</span></dt>
<dd><p>Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., … Lerchner, A. (2016 , November). Beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. <em>ICLR 2017</em>. URL: <a class="reference external" href="https://openreview.net/forum?id=Sy2fzU9gl">https://openreview.net/forum?id=Sy2fzU9gl</a></p>
</dd>
<dt class="bibtex label" id="hinton2006"><span class="brackets">Hinton &amp; Salakhutdinov, 2006</span></dt>
<dd><p>Hinton, G. E., &amp; Salakhutdinov, R. R. (2006 , July). Reducing the Dimensionality of Data with Neural Networks. <em>Science</em>, <em>313</em>(5786), 504–507. URL: <a class="reference external" href="https://science.sciencemag.org/content/313/5786/504">https://science.sciencemag.org/content/313/5786/504</a>, <a class="reference external" href="https://doi.org/10.1126/science.1127647">doi:10.1126/science.1127647</a></p>
</dd>
<dt class="bibtex label" id="hinton2015"><span class="brackets">Hinton et al., 2015</span></dt>
<dd><p>Hinton, G., Vinyals, O., &amp; Dean, J. (2015 , March). Distilling the Knowledge in a Neural Network. <em>arXiv:1503.02531 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1503.02531">http://arxiv.org/abs/1503.02531</a>, <a class="reference external" href="https://arxiv.org/abs/1503.02531">arXiv:1503.02531</a></p>
</dd>
<dt class="bibtex label" id="hinton2006a"><span class="brackets">Hinton et al., 2006</span></dt>
<dd><p>Hinton, G. E., Osindero, S., &amp; Teh, Y.-W. (2006 , July). A fast learning algorithm for deep belief nets. <em>Neural Computation</em>, <em>18</em>(7), 1527–1554. URL: <a class="reference external" href="https://doi.org/10.1162/neco.2006.18.7.1527">https://doi.org/10.1162/neco.2006.18.7.1527</a>, <a class="reference external" href="https://doi.org/10.1162/neco.2006.18.7.1527">doi:10.1162/neco.2006.18.7.1527</a></p>
</dd>
<dt class="bibtex label" id="hochreiter1997"><span class="brackets">Hochreiter &amp; Schmidhuber, 1997</span></dt>
<dd><p>Hochreiter, S., &amp; Schmidhuber, J. (1997 , November). Long short-term memory. <em>Neural computation</em>, <em>9</em>(8), 1735–80. URL: <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/9377276">http://www.ncbi.nlm.nih.gov/pubmed/9377276</a></p>
</dd>
<dt class="bibtex label" id="hochreiter1991"><span class="brackets">Hochreiter, 1991</span></dt>
<dd><p>Hochreiter, S. (1991). <em>Untersuchungen Zu Dynamischen Neuronalen Netzen</em> (Doctoral dissertation). TU München.</p>
</dd>
<dt class="bibtex label" id="hopfield1982a"><span class="brackets">Hopfield, 1982</span></dt>
<dd><p>Hopfield, J. J. (1982 , April). Neural networks and physical systems with emergent collective computational abilities. <em>Proceedings of the National Academy of Sciences</em>, <em>79</em>(8), 2554–2558. URL: <a class="reference external" href="https://www.pnas.org/content/79/8/2554">https://www.pnas.org/content/79/8/2554</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.79.8.2554">doi:10.1073/pnas.79.8.2554</a></p>
</dd>
<dt class="bibtex label" id="hopfield1983"><span class="brackets">Hopfield et al., 1983</span></dt>
<dd><p>Hopfield, J. J., Feinstein, D. I., &amp; Palmer, R. G. (1983 , July). `Unlearning’ has a stabilizing effect in collective memories. <em>Nature</em>, <em>304</em>(5922), 158–159. URL: <a class="reference external" href="https://www.nature.com/articles/304158a0">https://www.nature.com/articles/304158a0</a>, <a class="reference external" href="https://doi.org/10.1038/304158a0">doi:10.1038/304158a0</a></p>
</dd>
<dt class="bibtex label" id="huang2018"><span class="brackets">Huang et al., 2018</span></dt>
<dd><p>Huang, G., Liu, Z., van der Maaten, L., &amp; Weinberger, K. Q. (2018 , January). Densely Connected Convolutional Networks. <em>arXiv:1608.06993 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1608.06993">http://arxiv.org/abs/1608.06993</a>, <a class="reference external" href="https://arxiv.org/abs/1608.06993">arXiv:1608.06993</a></p>
</dd>
<dt class="bibtex label" id="ioffe2015"><span class="brackets">Ioffe &amp; Szegedy, 2015</span></dt>
<dd><p>Ioffe, S., &amp; Szegedy, C. (2015 , February). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. <em>arXiv:1502.03167 [cs.LG]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1502.03167">http://arxiv.org/abs/1502.03167</a>, <a class="reference external" href="https://arxiv.org/abs/1502.03167">arXiv:1502.03167</a></p>
</dd>
<dt class="bibtex label" id="isola2018"><span class="brackets">Isola et al., 2018</span></dt>
<dd><p>Isola, P., Zhu, J.-Y., Zhou, T., &amp; Efros, A. A. (2018 , November). Image-to-Image Translation with Conditional Adversarial Networks. <em>arXiv:1611.07004 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1611.07004">http://arxiv.org/abs/1611.07004</a>, <a class="reference external" href="https://arxiv.org/abs/1611.07004">arXiv:1611.07004</a></p>
</dd>
<dt class="bibtex label" id="izhikevich2003"><span class="brackets">Izhikevich, 2003</span></dt>
<dd><p>Izhikevich, E. M. (2003 , January). Simple model of spiking neurons. <em>IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council</em>, <em>14</em>(6), 1569–72. URL: <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/18244602">http://www.ncbi.nlm.nih.gov/pubmed/18244602</a>, <a class="reference external" href="https://doi.org/10.1109/TNN.2003.820440">doi:10.1109/TNN.2003.820440</a></p>
</dd>
<dt class="bibtex label" id="jaeger2001"><span class="brackets">Jaeger, 2001</span></dt>
<dd><p>Jaeger, H. (2001). <em>The “Echo State” Approach to Analysing and Training Recurrent Neural Networks</em>. Jacobs Universität Bremen.</p>
</dd>
<dt class="bibtex label" id="karras2020"><span class="brackets">Karras et al., 2020</span></dt>
<dd><p>Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., &amp; Aila, T. (2020 , March). Analyzing and Improving the Image Quality of StyleGAN. <em>arXiv:1912.04958 [cs, eess, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1912.04958">http://arxiv.org/abs/1912.04958</a>, <a class="reference external" href="https://arxiv.org/abs/1912.04958">arXiv:1912.04958</a></p>
</dd>
<dt class="bibtex label" id="kendall2016"><span class="brackets">Kendall et al., 2016</span></dt>
<dd><p>Kendall, A., Grimes, M., &amp; Cipolla, R. (2016 , February). PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization. <em>arXiv:1505.07427 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1505.07427">http://arxiv.org/abs/1505.07427</a>, <a class="reference external" href="https://arxiv.org/abs/1505.07427">arXiv:1505.07427</a></p>
</dd>
<dt class="bibtex label" id="kim2014"><span class="brackets">Kim, 2014</span></dt>
<dd><p>Kim, Y. (2014 , September). Convolutional Neural Networks for Sentence Classification. <em>arXiv:1408.5882 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1408.5882">http://arxiv.org/abs/1408.5882</a>, <a class="reference external" href="https://arxiv.org/abs/1408.5882">arXiv:1408.5882</a></p>
</dd>
<dt class="bibtex label" id="kingma2014"><span class="brackets">Kingma &amp; Ba, 2014</span></dt>
<dd><p>Kingma, D., &amp; Ba, J. (2014). Adam: A Method for Stochastic Optimization. <em>Proc. ICLR</em> (pp. 1–13). URL: <a class="reference external" href="http://arxiv.org/abs/1412.6980">http://arxiv.org/abs/1412.6980</a>, <a class="reference external" href="https://doi.org/10.1145/1830483.1830503">doi:10.1145/1830483.1830503</a></p>
</dd>
<dt class="bibtex label" id="kingma2013"><span class="brackets">Kingma &amp; Welling, 2013</span></dt>
<dd><p>Kingma, D. P., &amp; Welling, M. (2013 , December). Auto-Encoding Variational Bayes. <em>arXiv:1312.6114 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1312.6114">http://arxiv.org/abs/1312.6114</a>, <a class="reference external" href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a></p>
</dd>
<dt class="bibtex label" id="krizhevsky2012"><span class="brackets">Krizhevsky et al., 2012</span></dt>
<dd><p>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. <em>Advances in Neural Information Processing Systems (NIPS)</em>. URL: <a class="reference external" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></p>
</dd>
<dt class="bibtex label" id="krotov2016"><span class="brackets">Krotov &amp; Hopfield, 2016</span></dt>
<dd><p>Krotov, D., &amp; Hopfield, J. J. (2016 , September). Dense Associative Memory for Pattern Recognition. <em>arXiv:1606.01164 [cond-mat, q-bio, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1606.01164">http://arxiv.org/abs/1606.01164</a>, <a class="reference external" href="https://arxiv.org/abs/1606.01164">arXiv:1606.01164</a></p>
</dd>
<dt class="bibtex label" id="laje2013"><span class="brackets">Laje &amp; Buonomano, 2013</span></dt>
<dd><p>Laje, R., &amp; Buonomano, D. V. (2013 , July). Robust timing and motor patterns by taming chaos in recurrent neural networks. <em>Nature neuroscience</em>, <em>16</em>(7), 925–33. URL: <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/23708144">http://www.ncbi.nlm.nih.gov/pubmed/23708144</a>, <a class="reference external" href="https://doi.org/10.1038/nn.3405">doi:10.1038/nn.3405</a></p>
</dd>
<dt class="bibtex label" id="lapuschkin2019"><span class="brackets">Lapuschkin et al., 2019</span></dt>
<dd><p>Lapuschkin, S., Wäldchen, S., Binder, A., Montavon, G., Samek, W., &amp; Müller, K.-R. (2019 , March). Unmasking Clever Hans predictors and assessing what machines really learn. <em>Nature Communications</em>, <em>10</em>(1), 1096. URL: <a class="reference external" href="https://www.nature.com/articles/s41467-019-08987-4">https://www.nature.com/articles/s41467-019-08987-4</a>, <a class="reference external" href="https://doi.org/10.1038/s41467-019-08987-4">doi:10.1038/s41467-019-08987-4</a></p>
</dd>
<dt class="bibtex label" id="le2013"><span class="brackets">Le, 2013</span></dt>
<dd><p>Le, Q. V. (2013 , May). Building high-level features using large scale unsupervised learning. <em>2013 IEEE International Conference on Acoustics, Speech and Signal Processing</em> (pp. 8595–8598). Vancouver, BC, Canada: IEEE. URL: <a class="reference external" href="http://ieeexplore.ieee.org/document/6639343/">http://ieeexplore.ieee.org/document/6639343/</a>, <a class="reference external" href="https://doi.org/10.1109/ICASSP.2013.6639343">doi:10.1109/ICASSP.2013.6639343</a></p>
</dd>
<dt class="bibtex label" id="lecun1998"><span class="brackets">LeCun et al., 1998</span></dt>
<dd><p>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient Based Learning Applied to Document Recognition. <em>Proceedings of the IEEE</em>, <em>86</em>(11), 2278–2324. <a class="reference external" href="https://doi.org/10.1109/5.726791">doi:10.1109/5.726791</a></p>
</dd>
<dt class="bibtex label" id="li2018"><span class="brackets">Li et al., 2018</span></dt>
<dd><p>Li, H., Xu, Z., Taylor, G., Studer, C., &amp; Goldstein, T. (2018 , November). Visualizing the Loss Landscape of Neural Nets. <em>arXiv:1712.09913 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1712.09913">http://arxiv.org/abs/1712.09913</a>, <a class="reference external" href="https://arxiv.org/abs/1712.09913">arXiv:1712.09913</a></p>
</dd>
<dt class="bibtex label" id="lillicrap2016"><span class="brackets">Lillicrap et al., 2016</span></dt>
<dd><p>Lillicrap, T. P., Cownden, D., Tweed, D. B., &amp; Akerman, C. J. (2016 , November). Random synaptic feedback weights support error backpropagation for deep learning. <em>Nature Communications</em>, <em>7</em>(1), 1–10. URL: <a class="reference external" href="https://www.nature.com/articles/ncomms13276">https://www.nature.com/articles/ncomms13276</a>, <a class="reference external" href="https://doi.org/10.1038/ncomms13276">doi:10.1038/ncomms13276</a></p>
</dd>
<dt class="bibtex label" id="liu2016"><span class="brackets">Liu et al., 2016</span></dt>
<dd><p>Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., &amp; Berg, A. C. (2016). SSD: Single Shot MultiBox Detector. <em>arXiv:1512.02325 [cs]</em>, <em>9905</em>, 21–37. URL: <a class="reference external" href="http://arxiv.org/abs/1512.02325">http://arxiv.org/abs/1512.02325</a>, <a class="reference external" href="https://arxiv.org/abs/1512.02325">arXiv:1512.02325</a>, <a class="reference external" href="https://doi.org/10.1007/978-3-319-46448-0_2">doi:10.1007/978-3-319-46448-0_2</a></p>
</dd>
<dt class="bibtex label" id="maas2013"><span class="brackets">Maas et al., 2013</span></dt>
<dd><p>Maas, A. L., Hannun, A. Y., &amp; Ng, A. Y. (2013). Rectifier Nonlinearities Improve Neural Network Acoustic Models. <em>ICML</em> (p. 6).</p>
</dd>
<dt class="bibtex label" id="maass2002"><span class="brackets">Maass et al., 2002</span></dt>
<dd><p>Maass, W., Natschläger, T., &amp; Markram, H. (2002 , November). Real-time computing without stable states: a new framework for neural computation based on perturbations. <em>Neural computation</em>, <em>14</em>(11), 2531–60. URL: <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/12433288">http://www.ncbi.nlm.nih.gov/pubmed/12433288</a>, <a class="reference external" href="https://doi.org/10.1162/089976602760407955">doi:10.1162/089976602760407955</a></p>
</dd>
<dt class="bibtex label" id="malinowski2015"><span class="brackets">Malinowski et al., 2015</span></dt>
<dd><p>Malinowski, M., Rohrbach, M., &amp; Fritz, M. (2015 , October). Ask Your Neurons: A Neural-based Approach to Answering Questions about Images. <em>arXiv:1505.01121 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1505.01121">http://arxiv.org/abs/1505.01121</a>, <a class="reference external" href="https://arxiv.org/abs/1505.01121">arXiv:1505.01121</a></p>
</dd>
<dt class="bibtex label" id="mceliece1987"><span class="brackets">McEliece et al., 1987</span></dt>
<dd><p>McEliece, R., Posner, E., Rodemich, E., &amp; Venkatesh, S. (1987 , July). The capacity of the Hopfield associative memory. <em>IEEE Transactions on Information Theory</em>, <em>33</em>(4), 461–482. <a class="reference external" href="https://doi.org/10.1109/TIT.1987.1057328">doi:10.1109/TIT.1987.1057328</a></p>
</dd>
<dt class="bibtex label" id="mcinnes2020"><span class="brackets">McInnes et al., 2020</span></dt>
<dd><p>McInnes, L., Healy, J., &amp; Melville, J. (2020 , September). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. <em>arXiv:1802.03426 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1802.03426">http://arxiv.org/abs/1802.03426</a>, <a class="reference external" href="https://arxiv.org/abs/1802.03426">arXiv:1802.03426</a></p>
</dd>
<dt class="bibtex label" id="mikolov2013"><span class="brackets">Mikolov et al., 2013</span></dt>
<dd><p>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013 , September). Efficient Estimation of Word Representations in Vector Space. <em>arXiv:1301.3781 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1301.3781">http://arxiv.org/abs/1301.3781</a>, <a class="reference external" href="https://arxiv.org/abs/1301.3781">arXiv:1301.3781</a></p>
</dd>
<dt class="bibtex label" id="mirza2014"><span class="brackets">Mirza &amp; Osindero, 2014</span></dt>
<dd><p>Mirza, M., &amp; Osindero, S. (2014 , November). Conditional Generative Adversarial Nets. <em>arXiv:1411.1784 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1411.1784">http://arxiv.org/abs/1411.1784</a>, <a class="reference external" href="https://arxiv.org/abs/1411.1784">arXiv:1411.1784</a></p>
</dd>
<dt class="bibtex label" id="nowozin2016"><span class="brackets">Nowozin et al., 2016</span></dt>
<dd><p>Nowozin, S., Cseke, B., &amp; Tomioka, R. (2016 , June). F-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. <em>arXiv:1606.00709 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1606.00709">http://arxiv.org/abs/1606.00709</a>, <a class="reference external" href="https://arxiv.org/abs/1606.00709">arXiv:1606.00709</a></p>
</dd>
<dt class="bibtex label" id="olshausen1997"><span class="brackets">Olshausen &amp; Field, 1997</span></dt>
<dd><p>Olshausen, B. A., &amp; Field, D. J. (1997 , December). Sparse coding with an overcomplete basis set: A strategy employed by V1? <em>Vision Research</em>, <em>37</em>(23), 3311–3325. URL: <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S0042698997001697">http://www.sciencedirect.com/science/article/pii/S0042698997001697</a>, <a class="reference external" href="https://doi.org/10.1016/S0042-6989(97)00169-7">doi:10.1016/S0042-6989(97)00169-7</a></p>
</dd>
<dt class="bibtex label" id="radford2015"><span class="brackets">Radford et al., 2015</span></dt>
<dd><p>Radford, A., Metz, L., &amp; Chintala, S. (2015 , November). Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. <em>arXiv:1511.06434 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1511.06434">http://arxiv.org/abs/1511.06434</a>, <a class="reference external" href="https://arxiv.org/abs/1511.06434">arXiv:1511.06434</a></p>
</dd>
<dt class="bibtex label" id="ramsauer2020"><span class="brackets">Ramsauer et al., 2020</span></dt>
<dd><p>Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., … Hochreiter, S. (2020 , December). Hopfield Networks is All You Need. <em>arXiv:2008.02217 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/2008.02217">http://arxiv.org/abs/2008.02217</a>, <a class="reference external" href="https://arxiv.org/abs/2008.02217">arXiv:2008.02217</a></p>
</dd>
<dt class="bibtex label" id="razavi2019"><span class="brackets">Razavi et al., 2019</span></dt>
<dd><p>Razavi, A., van den Oord, A., &amp; Vinyals, O. (2019 , June). Generating Diverse High-Fidelity Images with VQ-VAE-2. <em>arXiv:1906.00446 [cs, stat]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1906.00446">http://arxiv.org/abs/1906.00446</a>, <a class="reference external" href="https://arxiv.org/abs/1906.00446">arXiv:1906.00446</a></p>
</dd>
<dt class="bibtex label" id="redmon2016"><span class="brackets">Redmon et al., 2016</span></dt>
<dd><p>Redmon, J., Divvala, S., Girshick, R., &amp; Farhadi, A. (2016 , May). You Only Look Once: Unified, Real-Time Object Detection. <em>arXiv:1506.02640 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1506.02640">http://arxiv.org/abs/1506.02640</a>, <a class="reference external" href="https://arxiv.org/abs/1506.02640">arXiv:1506.02640</a></p>
</dd>
<dt class="bibtex label" id="redmon2016a"><span class="brackets">Redmon &amp; Farhadi, 2016</span></dt>
<dd><p>Redmon, J., &amp; Farhadi, A. (2016 , December). YOLO9000: Better, Faster, Stronger. <em>arXiv:1612.08242 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1612.08242">http://arxiv.org/abs/1612.08242</a>, <a class="reference external" href="https://arxiv.org/abs/1612.08242">arXiv:1612.08242</a></p>
</dd>
<dt class="bibtex label" id="redmon2018"><span class="brackets">Redmon &amp; Farhadi, 2018</span></dt>
<dd><p>Redmon, J., &amp; Farhadi, A. (2018 , April). YOLOv3: An Incremental Improvement. <em>arXiv:1804.02767 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1804.02767">http://arxiv.org/abs/1804.02767</a>, <a class="reference external" href="https://arxiv.org/abs/1804.02767">arXiv:1804.02767</a></p>
</dd>
<dt class="bibtex label" id="reed2016"><span class="brackets">Reed et al., 2016</span></dt>
<dd><p>Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., &amp; Lee, H. (2016 , June). Generative Adversarial Text to Image Synthesis. <em>arXiv:1605.05396 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1605.05396">http://arxiv.org/abs/1605.05396</a>, <a class="reference external" href="https://arxiv.org/abs/1605.05396">arXiv:1605.05396</a></p>
</dd>
<dt class="bibtex label" id="ren2016"><span class="brackets">Ren et al., 2016</span></dt>
<dd><p>Ren, S., He, K., Girshick, R., &amp; Sun, J. (2016 , January). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. <em>arXiv:1506.01497 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1506.01497">http://arxiv.org/abs/1506.01497</a>, <a class="reference external" href="https://arxiv.org/abs/1506.01497">arXiv:1506.01497</a></p>
</dd>
<dt class="bibtex label" id="ronneberger2015"><span class="brackets">Ronneberger et al., 2015</span></dt>
<dd><p>Ronneberger, O., Fischer, P., &amp; Brox, T. (2015 , May). U-Net: Convolutional Networks for Biomedical Image Segmentation. <em>arXiv:1505.04597 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1505.04597">http://arxiv.org/abs/1505.04597</a>, <a class="reference external" href="https://arxiv.org/abs/1505.04597">arXiv:1505.04597</a></p>
</dd>
<dt class="bibtex label" id="rumelhart1986a"><span class="brackets">Rumelhart et al., 1986</span></dt>
<dd><p>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986 , October). Learning representations by back-propagating errors. <em>Nature</em>, <em>323</em>(6088), 533–536. URL: <a class="reference external" href="https://www.nature.com/articles/323533a0">https://www.nature.com/articles/323533a0</a>, <a class="reference external" href="https://doi.org/10.1038/323533a0">doi:10.1038/323533a0</a></p>
</dd>
<dt class="bibtex label" id="salimans2016"><span class="brackets">Salimans et al., 2016</span></dt>
<dd><p>Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., &amp; Chen, X. (2016 , June). Improved Techniques for Training GANs. <em>arXiv:1606.03498 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1606.03498">http://arxiv.org/abs/1606.03498</a>, <a class="reference external" href="https://arxiv.org/abs/1606.03498">arXiv:1606.03498</a></p>
</dd>
<dt class="bibtex label" id="simonyan2015"><span class="brackets">Simonyan &amp; Zisserman, 2015</span></dt>
<dd><p>Simonyan, K., &amp; Zisserman, A. (2015). Very Deep Convolutional Networks for Large-Scale Image Recognition. <em>International Conference on Learning Representations (ICRL)</em>, pp. 1–14. URL: <a class="reference external" href="http://arxiv.org/abs/1409.1556">http://arxiv.org/abs/1409.1556</a>, <a class="reference external" href="https://doi.org/10.1016/j.infsof.2008.09.005">doi:10.1016/j.infsof.2008.09.005</a></p>
</dd>
<dt class="bibtex label" id="sohn2015"><span class="brackets">Sohn et al., 2015</span></dt>
<dd><p>Sohn, K., Lee, H., &amp; Yan, X. (2015). Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M., &amp; Garnett, R. (Eds.). Learning Structured Output Representation using Deep Conditional Generative Models. <em>Advances in Neural Information Processing Systems 28</em> (pp. 3483–3491). Curran Associates, Inc.</p>
</dd>
<dt class="bibtex label" id="springenberg2015"><span class="brackets">Springenberg et al., 2015</span></dt>
<dd><p>Springenberg, J. T., Dosovitskiy, A., Brox, T., &amp; Riedmiller, M. (2015 , April). Striving for Simplicity: The All Convolutional Net. <em>arXiv:1412.6806 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1412.6806">http://arxiv.org/abs/1412.6806</a>, <a class="reference external" href="https://arxiv.org/abs/1412.6806">arXiv:1412.6806</a></p>
</dd>
<dt class="bibtex label" id="srivastava2014"><span class="brackets">Srivastava et al., 2014</span></dt>
<dd><p>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. <em>Journal of Machine Learning Research</em>, <em>15</em>(56), 1929–1958. URL: <a class="reference external" href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a></p>
</dd>
<dt class="bibtex label" id="srivastava2015"><span class="brackets">Srivastava et al., 2015</span></dt>
<dd><p>Srivastava, R. K., Greff, K., &amp; Schmidhuber, J. (2015 , November). Highway Networks. <em>arXiv:1505.00387 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1505.00387">http://arxiv.org/abs/1505.00387</a>, <a class="reference external" href="https://arxiv.org/abs/1505.00387">arXiv:1505.00387</a></p>
</dd>
<dt class="bibtex label" id="sussillo2009"><span class="brackets">Sussillo &amp; Abbott, 2009</span></dt>
<dd><p>Sussillo, D., &amp; Abbott, L. F. (2009 , August). Generating coherent patterns of activity from chaotic neural networks. <em>Neuron</em>, <em>63</em>(4), 544–57. URL: <a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/19709635">http://www.ncbi.nlm.nih.gov/pubmed/19709635</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuron.2009.07.018">doi:10.1016/j.neuron.2009.07.018</a></p>
</dd>
<dt class="bibtex label" id="sutskever2014"><span class="brackets">Sutskever et al., 2014</span></dt>
<dd><p>Sutskever, I., Vinyals, O., &amp; Le, Q. V. (2014 , December). Sequence to Sequence Learning with Neural Networks. <em>arXiv:1409.3215 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1409.3215">http://arxiv.org/abs/1409.3215</a>, <a class="reference external" href="https://arxiv.org/abs/1409.3215">arXiv:1409.3215</a></p>
</dd>
<dt class="bibtex label" id="szegedy2015"><span class="brackets">Szegedy et al., 2015</span></dt>
<dd><p>Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., &amp; Wojna, Z. (2015 , December). Rethinking the Inception Architecture for Computer Vision. <em>arXiv:1512.00567 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1512.00567">http://arxiv.org/abs/1512.00567</a>, <a class="reference external" href="https://arxiv.org/abs/1512.00567">arXiv:1512.00567</a></p>
</dd>
<dt class="bibtex label" id="taigman2014"><span class="brackets">Taigman et al., 2014</span></dt>
<dd><p>Taigman, Y., Yang, M., Ranzato, Marc’Aurelio, &amp; Wolf, L. (2014 , June). DeepFace: Closing the Gap to Human-Level Performance in Face Verification. <em>2014 IEEE Conference on Computer Vision and Pattern Recognition</em> (pp. 1701–1708). Columbus, OH, USA: IEEE. URL: <a class="reference external" href="https://ieeexplore.ieee.org/document/6909616">https://ieeexplore.ieee.org/document/6909616</a>, <a class="reference external" href="https://doi.org/10.1109/CVPR.2014.220">doi:10.1109/CVPR.2014.220</a></p>
</dd>
<dt class="bibtex label" id="tanaka2019a"><span class="brackets">Tanaka et al., 2019</span></dt>
<dd><p>Tanaka, G., Yamane, T., Héroux, J. B., Nakane, R., Kanazawa, N., Takeda, S., … Hirose, A. (2019 , July). Recent advances in physical reservoir computing: A review. <em>Neural Networks</em>, <em>115</em>, 100–123. URL: <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S0893608019300784">http://www.sciencedirect.com/science/article/pii/S0893608019300784</a>, <a class="reference external" href="https://doi.org/10.1016/j.neunet.2019.03.005">doi:10.1016/j.neunet.2019.03.005</a></p>
</dd>
<dt class="bibtex label" id="oord2016"><span class="brackets">Oord et al., 2016</span></dt>
<dd><p>van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., … Kavukcuoglu, K. (2016 , September). WaveNet: A Generative Model for Raw Audio. <em>arXiv:1609.03499 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1609.03499">http://arxiv.org/abs/1609.03499</a>, <a class="reference external" href="https://arxiv.org/abs/1609.03499">arXiv:1609.03499</a></p>
</dd>
<dt class="bibtex label" id="vaswani2017"><span class="brackets">Vaswani et al., 2017</span></dt>
<dd><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017 , June). Attention Is All You Need. <em>arXiv:1706.03762 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a>, <a class="reference external" href="https://arxiv.org/abs/1706.03762">arXiv:1706.03762</a></p>
</dd>
<dt class="bibtex label" id="vincent2010"><span class="brackets">Vincent et al., 2010</span></dt>
<dd><p>Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., &amp; Manzagol, P.-A. (2010). Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion. <em>Journal of Machine Learning Research</em>, p. 38.</p>
</dd>
<dt class="bibtex label" id="vinyals2015"><span class="brackets">Vinyals et al., 2015</span></dt>
<dd><p>Vinyals, O., Toshev, A., Bengio, S., &amp; Erhan, D. (2015 , April). Show and Tell: A Neural Image Caption Generator. <em>arXiv:1411.4555 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1411.4555">http://arxiv.org/abs/1411.4555</a>, <a class="reference external" href="https://arxiv.org/abs/1411.4555">arXiv:1411.4555</a></p>
</dd>
<dt class="bibtex label" id="wang2018b"><span class="brackets">Wang et al., 2018</span></dt>
<dd><p>Wang, B., Zheng, H., Liang, X., Chen, Y., Lin, L., &amp; Yang, M. (2018 , September). Toward Characteristic-Preserving Image-based Virtual Try-On Network. <em>arXiv:1807.07688 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1807.07688">http://arxiv.org/abs/1807.07688</a>, <a class="reference external" href="https://arxiv.org/abs/1807.07688">arXiv:1807.07688</a></p>
</dd>
<dt class="bibtex label" id="wu2016"><span class="brackets">Wu et al., 2016</span></dt>
<dd><p>Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., … Dean, J. (2016 , September). Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. <em>arXiv:1609.08144 [cs]</em>. URL: <a class="reference external" href="https://arxiv.org/abs/1609.08144v2">https://arxiv.org/abs/1609.08144v2</a>, <a class="reference external" href="https://arxiv.org/abs/1609.08144">arXiv:1609.08144</a></p>
</dd>
<dt class="bibtex label" id="xu2015"><span class="brackets">Xu et al., 2015</span></dt>
<dd><p>Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., … Bengio, Y. (2015). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. <em>Proceedings of the 32nd International Conference on Machine Learning - Volume 37</em> (pp. 2048–2057). JMLR.org. URL: <a class="reference external" href="http://dl.acm.org/citation.cfm?id=3045118.3045336">http://dl.acm.org/citation.cfm?id=3045118.3045336</a></p>
</dd>
<dt class="bibtex label" id="zhou2017"><span class="brackets">Zhou &amp; Tuzel, 2017</span></dt>
<dd><p>Zhou, Y., &amp; Tuzel, O. (2017 , November). VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. <em>arXiv:1711.06396 [cs]</em>. URL: <a class="reference external" href="http://arxiv.org/abs/1711.06396">http://arxiv.org/abs/1711.06396</a>, <a class="reference external" href="https://arxiv.org/abs/1711.06396">arXiv:1711.06396</a></p>
</dd>
<dt class="bibtex label" id="zhu2020"><span class="brackets">Zhu et al., 2020</span></dt>
<dd><p>Zhu, Y., Gao, T., Fan, L., Huang, S., Edmonds, M., Liu, H., … Zhu, S.-C. (2020 , February). Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense. <em>Engineering</em>. URL: <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S2095809920300345">http://www.sciencedirect.com/science/article/pii/S2095809920300345</a>, <a class="reference external" href="https://doi.org/10.1016/j.eng.2020.01.011">doi:10.1016/j.eng.2020.01.011</a></p>
</dd>
</dl>
</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="5-exercises/13-RNN-solution.html" title="previous page"><span class="section-number">13.2. </span>Recurrent neural networks</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Julien Vitay - julien.vitay@informatik.tu-chemnitz.de<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            Technische Universität Chemnitz - Faculty of Computer Science - Professorship for Artificial Intelligence
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>